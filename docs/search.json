[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Answers to selected exercises",
    "section": "",
    "text": "Preface\nThis website makes available solutions to selected exercises from the new Cambridge University Press text, due to appear in published form in May or June 2024:\n\n“A Practical Guide to Data Analysis Using R – An Example-Based Approach”, by John H Maindonald, W John Braun, and Jeffrey L Andrews.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "ch1.html",
    "href": "ch1.html",
    "title": "1  Answers to Selected Chapter 1 Exercises",
    "section": "",
    "text": "library(DAAG)\n\n\n\nExercise 1\n\nThe data frame DAAG::orings has details of damage that had occurred in US space shuttle launches prior to the disastrous Challenger launch of January 28, 1986. Observations in rows 1, 2, 4, 11, 13, and 18 were shown in the pre-launch charts used in deciding whether to proceed with the launch, with remaining rows omitted.\nCompare plots of Total incidents against Temperature: (i) including only the observations shown in the pre-launch charts; and (ii) using all rows of data. What did the full set of data strongly suggest that was less clear from the plot that showed only the selected rows?\n\nUse the following to extract rows that hold the data that were presented in the pre-launch charts:\n\norings86 &lt;- DAAG::orings[c(1,2,4,11,13,18), ]\nlibrary(lattice)\ngph1 &lt;- xyplot(Total ~ Temperature, data=orings86, pch=16)\ngph2 &lt;- xyplot(Total ~ Temperature, data=DAAG::orings)\nc(\"Points in pre-launch charts\"=gph1,\"All Points\" = gph2, y.same=TRUE)\n\n\n\n\n\n\n\n\nPoints are best shown with filled symbols in the first plot, and with open symbols in the second plot. (Why?)\n\n\nExercise 7\n\nPlot a histogram of the earconch measurements for the possum data. The distribution should appear bimodal (two peaks). This is a simple indication of clustering, possibly due to sex differences. Obtain side-by-side boxplots of the male and female measurements. How do these measurement distributions differ? Can you predict what the corresponding histograms would look like? Plot them to check your answer.\n\n\n\n\n\n\n\n\n\n\n\npossum &lt;- DAAG::possum\npar(mfrow=c(1,2), mar=c(4.1,4.1,1.6,0.6))\nhist(possum$earconch, main=\"\")\nboxplot(earconch ~ sex, data=possum, horizontal=TRUE)\n\nThe left panel shows a histogram of possum ear conch measurements. The right panel shows side by side boxplots of the measurements, one for each sex. A horizontal layout is often advantageous.\nNote the alternative to boxplot() that uses the lattice function bwplot(). Placing sex on the left of the graphics formula leads to horizontal boxplots.\n\nbwplot(sex ~ earconch, data=possum)\n\nThe following uses the lattice function to give side by side histograms:\n\nhistogram(~ earconch | sex, data=possum)\n\n\n\n\n\n\n\n\nDensity plots, in addition to avoiding what has to be a largely arbitrary choice of cutpoints, are easy to overlay.\n\ndensityplot(~earconch, data=DAAG::possum, groups=sex, \n            auto.key=list(columns=2))\n\n\n\n\n\n\n\n\n\n\nExercise 8\n\nFor the data frame ais (DAAG package), draw graphs that show how the values of the hematological measures (red cell count, hemoglobin concentration, hematocrit, white cell count and plasma ferritin concentration) vary with the sport and sex of the athlete.\n\nThe plots that follow show one possibility that gives a relatively compact presentation:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe final 2 in layout=c(2,3,2) spills the panels for the final two measures over onto a second page.\n\n\nExercise 14\n\nAn experimenter intends to arrange experimental plots in four blocks. In each block there are seven plots, one for each of seven treatments. Use the function to find four random permutations of the numbers 1 to 7 that will be used, one set in each block, to make the assignments of treatments to plots.\n\n\nfor(i in 1:4)print(sample(1:7))\n\n[1] 7 6 1 5 2 4 3\n[1] 5 3 7 6 4 2 1\n[1] 4 2 7 1 6 5 3\n[1] 2 5 7 4 1 6 3\n\n## Store results in the columns of a matrix\n## The following is mildly cryptic\nsapply(1:4, function(x)sample(1:7))  \n\n     [,1] [,2] [,3] [,4]\n[1,]    4    4    2    6\n[2,]    3    5    7    5\n[3,]    1    6    6    3\n[4,]    7    3    4    4\n[5,]    6    7    5    2\n[6,]    5    2    3    7\n[7,]    2    1    1    1\n\n\n\n\nExercise 15\n\nThe following data represent the total number of aberrant crypt foci (abnormal growths in the colon) observed in 7 rats that had been administered a single dose of the carcinogen azoxymethane and sacrificed after six weeks:\n87 53 72 90 78 85 83\nEnter these data and compute their sample mean and variance. Is the Poisson model appropriate for these data. To investigate how the sample variance and sample mean differ under the Poisson assumption, repeat the following simulation experiment several times:\n\nx &lt;- rpois(7, 78.3)\nmean(x); var(x)\n\n\n\ny &lt;- c(87, 53, 72, 90, 78, 85, 83)\nc(mean=mean(y), variance=var(y))\n\n     mean  variance \n 78.28571 159.90476 \n\n\nThen try\n\nx &lt;- rpois(7, 78.3)\nc(mean=mean(x), variance=var(x))\n\n    mean variance \n76.57143 36.95238 \n\n\nIt is unusual to get as big a difference between the mean and the variance as that observed for these data, making it doubtful that these data are from a Poisson distribution.\n\n\nExercise 21\n\nThe following code generates random normal numbers with a sequential dependence structure:\n\ny &lt;- rnorm(51) \nydep &lt;- y[-1] + y[-51] \nacf(y, main='A: iid normal values') \nacf(ydep, main='B: Sequentially dependent')\n\nRepeat this several times. There should be no consistent pattern in the acf plot for different iid (independently and identically distributed) random samples y, and a fairly consistent pattern in the acf plot for ydep that reflects the correlation that is introduced by adding to each value of y the next value in the sequence.\n\nThe following should be repeated several times:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn most plots, a lag 1 autocorrelation that is outside of the error bounds shown by the dashed horizontal lines should be evident in the second plot.\n\n\nExercise 22\n\nAssuming that the variability in egg length in the cuckoo eggs data is the same for all host birds, obtain an estimate of the pooled standard deviation as a way of summarizing this variability. [Hint: Remember to divide the appropriate sums of squares by the number of degrees of freedom remaining after estimating the six different means.]\n\n\ncuckoos &lt;- DAAG::cuckoos\nsapply(cuckoos, is.factor)   # Check which columns are factors\n\n length breadth species      id \n  FALSE   FALSE    TRUE   FALSE \n\nspecnam &lt;- levels(cuckoos$species)\nss &lt;- 0\nndf &lt;- 0\nfor(nam in specnam){\n  lgth &lt;- cuckoos$length[cuckoos$species==nam]\n  ss &lt;- ss + sum((lgth - mean(lgth))^2)\n  ndf &lt;- ndf + length(lgth) - 1\n}\nsqrt(ss/ndf)\n\n[1] 0.9051987\n\n\nA more cryptic solution is:\n\ndiffs &lt;- unlist(sapply(split(cuckoos$length, cuckoos$species), \n                function(x)x-mean(x)))\ndf &lt;- unlist(sapply(split(cuckoos$length, cuckoos$species), \n             function(x)length(x) - 1))\nsqrt(sum(diffs^2)/sum(df))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Answers to Selected Chapter 1 Exercises</span>"
    ]
  },
  {
    "objectID": "ch2.html",
    "href": "ch2.html",
    "title": "2  Answers to Selected Chapter 2 Exercises",
    "section": "",
    "text": "library(DAAG)\n\n\n\nExercise 2\n\nThe table UCBAdmissions was discussed in Subsection 2.2.1. The following gives a table that adds the 2 \\(\\times\\) 2 tables of admission data over all departments:\n\n## UCBAdmissions is in the datasets package\n## For each combination of margins 1 and 2, calculate the sum\nUCBtotal &lt;- apply(UCBAdmissions, c(1,2), sum)\n\nWhat are the names of the two dimensions of this table?\n\nFrom the table UCBAdmissions, create mosaic plots for each faculty separately. (If necessary refer to the code given in the help page for UCBAdmissions.)\n\n\nCompare the information in the table UCBtotal with the result from applying the function mantelhaen.test() to the table UCBAdmissions. Compare the two sets of results, and comment on the difference.\n\n\n\nThe Mantel–Haenzel test is valid only if the male to female odds ratio for admission is similar across departments. The following code calculates the relevant odds ratios:\n\n\n\napply(UCBAdmissions, 3, function(x)\n      (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))\n\nIs the odds ratio consistent across departments? Which department(s) stand(s) out as different? What is the nature of the difference? \\end{enumerate} [For further information on the Mantel-Haenszel test, see the help page for mantelhaen.test.]\n\nUse dimnames(UCBAdmissions)[1:2] to get the names of the first two dimensions, which are Admit and Gender.\n\nFirst note the code needed to give a mosaic plot for the totals; the question does not ask for this. There is an excess of males and a deficit of females in the Admitted category.\n\n\npar(mar=c(3.1,3.1,2.6,1.1))\nUCBtotal &lt;- apply(UCBAdmissions, c(1,2), sum)\nmosaicplot(UCBtotal,col=TRUE)\n\nNow obtain the mosaic plots for each department separately.\n\noldpar &lt;- par(mfrow=c(2,3), mar=c(3.1,3.1,2.6,1), cex.main=0.8)           \nfor(i in 1:6)\n    mosaicplot(UCBAdmissions[,,i], xlab = \"Admit\", ylab = \"Sex\",\n               main = paste(\"Department\", LETTERS[i]), color=TRUE)\n\n\n\n\n\n\n\n\n\n\nMosaic plots are shown for each department separately. The greatest difference in the proportions in the two vertical columns is for Department A.\n\n\n\n\napply(UCBAdmissions, 3, function(x)(x[1,1]*x[2,2])/(x[1,2]*x[2,1]))\n\n        A         B         C         D         E         F \n0.3492120 0.8025007 1.1330596 0.9212838 1.2216312 0.8278727 \n\n\nThe odds ratio (male to female admissions) is much the lowest for Department A.\n\n\nExercise 3\n\nThe following fictitious data is designed to illustrate issues for combining data across tables.\n\n\n       Engineering        Sociology         Sum       \n              Male Female      Male Female Male Female\n                                                      \nAdmit           30     10        15     30   45     40\nDeny            30     10         5     10   35     20\n\n\n       Engineering        Sociology         Sum       \n              Male Female      Male Female Male Female\n                                                      \nAdmit           30     20        10     20   40     40\nDeny            30     10         5     25   35     35\n\n\nThe third dimension in each table is faculty, as required for using faculty as a stratification variable for the Mantel–Haenzel test. From the help page for mantelhaen.test(), extract and enter the code for the function woolf(). Apply the function woolf(), followed by the function mantelhaen.test(), to the data of each of Tables A and B. Explain, in words, the meaning of each of the outputs. Then apply the Mantel–Haenzel test to each of these tables.\n\n\ntabA &lt;- array(c(30, 30, 10, 10, 15, 5, 30, 10),\n                    dim=c(2, 2, 2))\ntabB &lt;- array(c(30, 30, 20, 10, 10, 5, 20, 25),\n                     dim=c(2, 2, 2))\ndimnames(tabA) &lt;- dimnames(tabB) &lt;- \n  list(c('Admit','Deny'), c('Male','Female'), \n       c(\"Engineering\",'Sociology'))\n\n\n     woolf &lt;- function(x) {\n       x &lt;- x + 1 / 2\n       k &lt;- dim(x)[3]\n       or &lt;- apply(x, 3, function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))\n       w &lt;-  apply(x, 3, function(x) 1 / sum(1 / x))\n       1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w)) ^ 2), k - 1)\n     }           \nwoolf(tabA)\n\n[1] 0.9695992\n\n\nThe assumption of homogeneity (equal odds ratios for males and females in each of the two departments) appears acceptable.\n\nwoolf(tabB)\n\n[1] 0.04302033\n\n\nThere is evidence of department-specific biases.\n\nmantelhaen.test(tabA)\n\n\n    Mantel-Haenszel chi-squared test without continuity correction\n\ndata:  tabA\nMantel-Haenszel X-squared = 0, df = 1, p-value = 1\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.4565826 2.1901841\nsample estimates:\ncommon odds ratio \n                1 \n\n\nThe estimate of the common odds ratio is 1.\n\nmantelhaen.test(tabB)\n\n\n    Mantel-Haenszel chi-squared test with continuity correction\n\ndata:  tabB\nMantel-Haenszel X-squared = 0.014147, df = 1, p-value = 0.9053\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.448071 1.807749\nsample estimates:\ncommon odds ratio \n              0.9 \n\n\nThe common odds ratio is given as 0.9. However, because the odds ratio is not homogeneous within each of the two departments, this overall figure is, depending on its intended use, misleading.\n\n\nExercise 5\n\nFor constructing bootstrap confidence intervals for the correlation coefficient, it is advisable to work with the Fisher \\(z\\)-transformation of the correlation coefficient. The following lines of R code show how to obtain a bootstrap confidence interval for the \\(z\\)-transformed correlation between chest and belly in the possum data frame. The last step of the procedure is to apply the inverse of the \\(z\\)-transformation to the confidence interval to return it to the original scale. Run the following code and compare the resulting interval with the one computed without transformation. Is the \\(z\\)-transform necessary here?\n\nz.transform &lt;- function(r) .5*log((1+r)/(1-r))\nz.inverse &lt;- function(z) (exp(2*z)-1)/(exp(2*z)+1)\npossum.fun &lt;- function(data, indices) {\n  chest &lt;- data$chest[indices]\n  belly &lt;- data$belly[indices]\n  z.transform(cor(belly, chest))}\npossum.boot &lt;- boot(possum, possum.fun, R=999)\nz.inverse(boot.ci(possum.boot, type=\"perc\")$percent[4:5])\n  # See help(bootci.object).  The 4th and 5th elements of \n  # the percent list element hold the interval endpoints.\n\n\n\nsuppressPackageStartupMessages(library(boot))\n\n\n\n[1] 0.4789830 0.7139753\n\n\n\n\nExercise 6\n\nUse the function rexp() to simulate 100 exponential random numbers with rate .2. Obtain a density plot for the observations. Find the sample mean of the observations. Compare with the result that would be obtained using the normal approximation, i.e., \\(pi/(2*n)\\).\n\n\n\n\n\n\n\n\n\n\nThe density plot is for 100 random values from an exponential distribution with rate = 0.2.\n\n## Code\nz &lt;- rexp(100, .2)\nplot(density(z, from=0), main=\"\")\n\nNotice the use of the argument from=0, to prevent density() from giving a positive density estimate to negative values.\nCompare mean(z) = 5.49 with 1/0.2 = 5.\n\n\nExercise 7\n\nLow doses of the insecticide toxaphene may cause weight gain in rats. A sample of 20 rats are given toxaphene in their diet, while a control group of 8 rats are not given toxaphene. Assume further that weight gain among the treated rats is normally distributed with a mean of 60g and standard deviation 30g, while weight gain among the control rats is normally distributed with a mean of 10g and a standard deviation of 50g. Using simulation, compare confidence intervals for the difference in mean weight gain, using the pooled variance estimate and the Welch approximation. Which type of interval is correct more often?\nRepeat the simulation experiment under the assumption that the standard deviations are 40g for both samples. Is there a difference between the two types of intervals now? Hint: Is one of the methods giving systematically larger confidence intervals? Which type of interval do you think is best?\n\n\n\"Welch.pooled.comparison\" &lt;-\n  function(n1=20, n2=8, mean1=60, mean2=10,\n  sd1=30, sd2=50, nsim=1000) {\n    Welch.count &lt;- logical(nsim)\n    pooled.count &lt;- logical(nsim)\n    Welch.length &lt;- numeric(nsim)\n    pooled.length &lt;- numeric(nsim)\n    mean.diff &lt;- mean1-mean2\n    for (i in 1:1000){\n        x &lt;- rnorm(n1, mean=mean1, sd=sd1)\n        y &lt;- rnorm(n2, mean=mean2, sd=sd2)\n        t1conf.int &lt;- t.test(x, y)$conf.int\n        t2conf.int &lt;- t.test(x, y, var.equal=TRUE)$conf.int\n        t1correct &lt;- (t1conf.int[1] &lt; mean.diff) & (t1conf.int[2] &gt;\n            mean.diff)\n        t2correct &lt;- (t2conf.int[1] &lt; mean.diff) & (t2conf.int[2] &gt;\n            mean.diff)\n        Welch.count[i] &lt;- t1correct\n        pooled.count[i] &lt;- t2correct\n        Welch.length[i] &lt;- diff(t1conf.int)\n        pooled.length[i] &lt;- diff(t2conf.int)\n    }\n    c(\"Welch.proportion.correct\"=mean(Welch.count),\n           \"pooled.proportion.correct\"=mean(pooled.count),\n           \"Welch.length.avg\" = mean(Welch.length),\n           \"pooled.length.avg\" = mean(pooled.length))\n}\nWelch.pooled.comparison()\n\n Welch.proportion.correct pooled.proportion.correct          Welch.length.avg \n                  0.94100                   0.89000                  82.81857 \n        pooled.length.avg \n                 61.98452 \n\nWelch.pooled.comparison(sd1=40, sd2=40)\n\n Welch.proportion.correct pooled.proportion.correct          Welch.length.avg \n                  0.94000                   0.93900                  71.86132 \n        pooled.length.avg \n                 68.56197 \n\n\n\n\nExercise 8\n\n*Experiment with the DAAG::pair65 example and plot various views of the likelihood function, either as a surface using the persp() function or as one-dimensional profiles using the curve() function. Is there a single maximizer: Where does it occur?\n\nFirst, check the mean and the SD.\n\nwith(pair65, heated-ambient)\n\n[1] 19  8  4  1  6 10  6 -3  6\n\nmean(with(pair65, heated-ambient))\n\n[1] 6.333333\n\nsd(with(pair65, heated-ambient))\n\n[1] 6.103278\n\n\nNow create and use a function that calculates the likelihood, given mu and sigma\n\nfunlik &lt;- function(mu, sigma, x=with(pair65, heated-ambient))\n  prod(dnorm(x, mu, sigma))\n\nNext, calculate a vector of values of mu, and a vector of values of sigma\n\nmuval &lt;- seq(from=2, to=12, by=0.5)     # Values about mu=6.33\nsigval &lt;- seq(from=1, to=15, by=0.5)    # Values about mu=6.10\n\nNow calculate an array of loglikelihoods\n\nloglikArray &lt;- function(mu, sigma, d=with(pair65, heated-ambient)){\n  xx &lt;- matrix(0, nrow=length(mu), ncol=length(sigma))\n  for (j in seq(along=sigma)) for (i in seq(along=mu))\n    xx[i,j] &lt;- log(funlik(mu[i], sigma[j], d))\n  xx\n}\nloglik &lt;- loglikArray(mu=muval, sigma=sigval)\n\nPanel B shows a wider range of values of mu, and a narrower range of values of sigma, than in Panel B:\n\npar(mfrow=c(1,2))\npersp(x=muval, y=sigval, loglik, main=\"A: Initial choice of value ranges\")\nmuval &lt;- seq(from=-1, to=14, by=0.5)\nsigval &lt;- seq(from=3, to=12, by=0.2)\nloglik &lt;- loglikArray(mu=muval, sigma=sigval)\npersp(x=muval, y=sigval, loglik, main=\"B: Adjusted value ranges\")\n\n\n\n\n\n\n\n\nTry also\n\npar(mfrow=c(1,2))\ncontour(muval, sigval, loglik)\nfilled.contour(muval, sigval, loglik)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 9\n\n*Suppose the mean reaction time to a particular stimulus has been estimated in several previous studies, and it appears to be approximately normally distributed with mean 0.35 seconds with standard deviation 0.1 seconds. On the basis of 10 new observations, the mean reaction time is estimated to be 0.45 seconds with an estimated standard deviation of 0.15 seconds. Based on the sample information, what is the maximum likelihood estimator for the true mean reaction time? What is the Bayes’ estimate of the mean reaction time.\n\nFollowing Section 2.9.1 the posterior density of the mean is normal with mean \\[ \\frac{n \\bar{y} + \\mu_0 \\sigma^2/\\sigma_0^2}{n + \\sigma^2/\\sigma_0^2} \\] and variance \\[ \\frac{\\sigma^2}{n + \\sigma^2/\\sigma_0^2}\\] where, here \\[  \\mu_0 = 0.35, \\sigma_0 = 0.1, \\quad \\bar{y} = 0.45, n = 10,\n\\sigma = 0.15 \\] Thus the posterior mean and variance of the mean are:\n\nprint(c(mean = (10 * 0.45 + 0.35 * 0.15^2/0.1^2)/(10 + 0.15^2/0.1^2)))\n\n     mean \n0.4316327 \n\nprint(c(variance = 0.1^2/(10 + 0.15^2/0.1^2)))\n\n    variance \n0.0008163265 \n\n\nThe posterior mean is the Bayes’ estimate of the mean.\n\n\nExercise 10\n\nUse the robust regression function MASS::rlm() to fit lines to the data in elastic1 and elastic2. Compare the results with those from use of lm(). Compare regression coefficients, standard errors of coefficients, and plots of residuals against fitted values.\n\nThe required regressions are as follows:\n\ne1.lm &lt;- lm(distance ~ stretch, data=elastic1)\ne2.lm &lt;- lm(distance ~ stretch, data=elastic2)\n\nThe fitted values and standard errors of the fits are then:\n\npredict(e1.lm, se.fit=TRUE)\n\n$fit\n       1        2        3        4        5        6        7 \n183.1429 235.7143 196.2857 209.4286 170.0000 156.8571 222.5714 \n\n$se.fit\n[1]  6.586938 10.621119  5.891537  6.586938  8.331891 10.621119  8.331891\n\n$df\n[1] 5\n\n$residual.scale\n[1] 15.58754\n\n\nThe standard errors are somewhat smaller for the second data set than for the first\nThe robust regression fits can be obtained as follows:\n\nsuppressPackageStartupMessages(library(MASS))\ne1.rlm &lt;- rlm(distance ~ stretch, data=elastic1)\ne2.rlm &lt;- rlm(distance ~ stretch, data=elastic2)\n\nThe residual plots can be obtained for rlm() in the same was as for . It may however be more insightful to overlay the rlm() plots on the lm() plots.\n\npar(mfrow=c(1,2))\nplot(e1.lm, which=1, add.smooth=FALSE)\npoints(resid(e1.rlm) ~ fitted(e1.rlm), col=2, pch=2)\nplot(e2.lm, which=1, add.smooth=FALSE)\npoints(resid(e2.rlm) ~ fitted(e2.rlm), col=2, pch=2)\n\n\n\n\n\n\n\n\nThe figure shows overlaid plots of residuals versus fitted values, for the dataframes elastic1 (left panel) and elastic2 (right panel). Circles are for the lm fit and triangles for the rlm fit.\nFor comparison purposes, we include residual plots for the ordinary regression fits. Note, in particular, how the robust regression has reduced the weight of the outlying observation in the first data set. The residual at that point is larger than it was using ordinary least-squares. The residual plots for the ordinary and robust fits are very similar for the second data set, since there are no outlying observations.\nAs can be seen in the summaries below, the ordinary and robust fits for the first data set give quite different estimates of the slope and intercept. The robust fit is more in line with both sets of results obtained for the second data set.\nNote also the downward effect of the robust regression on the residual standard error. This is again due to the down-weighting of the outlying observation.\nFor further details, run the following code:\n\nsummary(e1.rlm)\nsummary(e1.lm)\nsummary(e2.rlm)\nsummary(e2.lm)\n\n\n\nExercise 11\n\nIn the data set pressure (datasets), examine the dependence of pressure on temperature.\n[The relevant theory is that associated with the Claudius-Clapeyron equation, by which the logarithm of the vapor pressure is approximately inversely proportional to the absolute temperature. For further details of the Claudius-Clapeyron equation, search on the internet, or look in a suitable reference text.]\n\nThe following fits the Claudius-Claperon equation\n\npar(mfrow=c(1,2))\npressure$K &lt;- pressure$temperature+273\nplot(log(pressure) ~ I(1/K), data=pressure)\np.lm &lt;- lm(log(pressure) ~  I(1/K), data=pressure)\ntitle(main='A: Points, with fitted line')\nplot(p.lm, which=1, main='B: Residuals vs fitted values')\n\n\n\n\n\n\n\n\nLook also at the adjusted R-squared statistic:\n\nprint(summary(p.lm)$adj.r.squared, digits=6)\n\n[1] 0.999888\n\n\nThe plot in Panel A, and the adjusted R-squared statistic, show a very close fit. Nonetheless, Panel B shows systematic departures from the fitted line.\nPanel A in the figure below shows large departures from the line that is fitted on a logarithmic scale at the lowest temperatures, where the pressure is also lowest. Working with log(pressure) exaggerates the weight given to low values for pressure, relative to high values. The linear equation \\[ \\log(pressure) = a + \\frac{b}{K} \\] can be rewritten: \\[\npressure = \\mbox{exp}(a)\\mbox{exp}(\\frac{b}{K})\n\\] The function nls() can then be used for a fit of this nonlinear version of the model, thus giving equal weight to all values of pressure. Panel B shows residuals whose scatter is then much more similar across all values of pressure.\n\npar(mfrow=c(1,2))\nplot(resid(p.lm) ~ K, data=pressure)\ntitle(main='A: Residuals from lm fit, vs `K`')\nab &lt;- coef(p.lm)\np.nls &lt;- nls(pressure ~ A*exp(b/K), data=pressure, start=list(A=exp(ab[1]),b=ab[2]))\nplot(resid(p.nls) ~ fitted(p.nls))\ntitle(main='B: Residuals from nls fit')\n\n\n\n\n\n\n\n\nThe use of nls() for nonlinear least squares is discussed in Subsection 3.8.4.\n\n\nExercise 15\n\n*A Markov chain is a data sequence which has a special kind of dependence. For example, a fair coin is tossed repetitively by a player who begins with $2. If `heads’ appear, the player receives one dollar; otherwise, she pays one dollar. The game stops when the player has either $0 or $5. The amount of money that the player has before any coin flip can be recorded – this is a Markov chain. A possible sequence of plays is as follows:\nPlayer's fortune:  2  1  2  3  4  3  2  3  2  3  2  1  0 \nCoin Toss result:  T  H  H  H  T  T  H  T  H  T  T  T \nNote that all we need to know in order to determine the player’s fortune at any time is the fortune at the previous time as well as the coin flip result at the current time. The probability of an increase in the fortune is .5 and the probability of a decrease in the fortune is .5. Such transition probabilities are usually summarized in a transition matrix:\n\\[ P = \\left[ \\begin{array}{c c c c c c} 1 & 0 & 0 & 0 & 0 & 0 \\\\\n                                 .5 & 0 & .5 & 0 & 0 & 0 \\\\\n                                  0 & .5 & 0 & .5 & 0 & 0 \\\\\n                                  0 & 0 & .5 & 0 & .5 & 0 \\\\\n                                  0 & 0 & 0 & .5 & 0 & .5 \\\\\n                                  0 & 0 & 0 & 0 & 0 & 1\\\\\n                                  \\end{array} \\right]\\]\nThe \\((i,j)\\) entry of this matrix refers to the probability of making a change from the value \\(i\\) to the value \\(j\\). Here, the possible values of \\(i\\) and \\(j\\) are \\(0, 1, 2, \\ldots, 5\\). According to the matrix, there is a probability of 0 of making a transition from $2 to $4 in one play, since the (2,4) element is 0; the probability of moving from $2 to $1 in one transition is 0.5, since the (2,1) element is 0.5.\nThe following function can be used to simulate \\(N\\) values of a Markov chain sequence, with transition matrix \\(P\\):\n\nMarkov &lt;- function (N=100, initial.value=1, P)\n{\n    X &lt;- numeric(N)\n    X[1] &lt;- initial.value + 1\n    n &lt;- nrow(P)\n    for (i in 2:N){\n    X[i] &lt;- sample(1:n, size=1, prob=P[X[i-1],])}\n    X - 1\n}\n## Set `stopval=c(0,5)` to stop when the player's fortune is $0 or $5\n\nSimulate 15 values of the coin flip game, starting with an initial value of $2.\n\nCode which may be used is:\n\nP &lt;- matrix(c(1, rep(0,5), rep(c(.5,0,.5, rep(0,4)),4), 0,1),\n            byrow=TRUE,nrow=6)\nMarkov(15, 2, P)\n\n\n\nExercise 15 – additional exercises\n\n\nSimulate 100 values of the Markov chain which has the following transition matrix. Save the result to a vector and use ts.plot() to plot the sequence. \\[ P = \\left[\n\\begin{array}{rrrrrr}\n0.10 & 0.90 & 0.00 & 0.00 & 0.00 & 0.00 \\\\\n0.50 & 0.00 & 0.50 & 0.00 & 0.00 & 0.00 \\\\\n0.00 & 0.50 & 0.00 & 0.50 & 0.00 & 0.00 \\\\\n0.00 & 0.00 & 0.50 & 0.00 & 0.50 & 0.00 \\\\\n0.00 & 0.00 & 0.00 & 0.50 & 0.00 & 0.50 \\\\\n0.00 & 0.00 & 0.00 & 0.00 & 1.00 & 0.00 \\\\\n\\end{array} \\right] \\]\nNow simulate 1000 values from the above Markov chain, and calculate the proportion of times the chain visits each of the states. It can be shown, using linear algebra, that in the long run, this Markov chain will visit the states according to the following stationary distribution\n\n 0         1         2         3         4         5\n 0.1098901 0.1978022 0.1978022 0.1978022 0.1978022 0.0989011\nThere is a result called the ergodic theorem which allows us to estimate this distribution by simulating the Markov chain for a long enough time. Compare your calculated proportions with above theoretical proportions. Repeat the experiment using 10000 simulated values; the calculated proportions should be even closer to the theoretically predicted proportions in that case.\nc. Simulate 100 values of the Markov chain which has the following transition matrix. Plot the sequence. Compare the results when the initial value is 1 with when the initial value is 3, 4, or 5. [When the initial value is 0 or 1, this Markov chain wanders a bit before settling down to its stationary distribution which is concentrated more on the values 4 and 5. This wandering period is sometimes called `burn-in’.] \\[ P = \\left[\n\\begin{array}{llllll}\n0.50 & 0.50 & 0    & 0    & 0    & 0    \\\\\n0.50 & 0.45 & 0.05 & 0    & 0    & 0    \\\\\n0    & 0.01 & 0    & 0.90 & 0.09 & 0    \\\\\n0    & 0    & 0.01 & 0.40 & 0.59 & 0    \\\\\n0    & 0    & 0    & 0.50 & 0    & 0.50 \\\\\n0    & 0    & 0    & 0    & 0.50 & 0.50 \\\\\n\\end{array} \\right] \\]\n\nHere is code that may be used for these calculations.\n\n\n\n\nPb &lt;- matrix(c(0.10,0.90,0.00,0.00,0.00,0.00,\n               0.50,0.00,0.50,0.00,0.00,0.00,\n               0.00,0.50,0.00,0.50,0.00,0.00,\n               0.00,0.00,0.50,0.00,0.50,0.00,\n               0.00,0.00,0.00,0.50,0.00,0.50,\n               0.00,0.00,0.00,0.00,1.00,0.00), \n             byrow=TRUE, nrow=6)\nxb &lt;- Markov(100, 1, Pb)\nxb\nts.plot(xb)\n\n\n\n\n\nxc &lt;- Markov(1000, 1, Pb)\ntable(xb)/1000  # one of several ways to calculate the proportions\nxc\nxc2 &lt;- Markov(10000, 1, Pb)\ntable(xc2)/10000\n\n\n\n\n\nPd &lt;- matrix(c(0.50, 0.50, 0, 0, 0, 0,\n               0.50, 0.45, 0.05, 0, 0, 0,\n               0, 0.01, 0, 0.90, 0.09, 0,\n               0, 0, 0.01, 0.40, 0.59, 0,\n               0, 0, 0, 0.50, 0, 0.50,\n               0, 0, 0, 0, 0.50, 0.50), \n             nrow=6, byrow=TRUE)\nThe following function may be helpful, in examining results.\n`plotmarkov` &lt;-\n  function(n=10000, start=1, window=100, transition=Pd){\n    xc2 &lt;- Markov(n, start, transition)\n    z4 &lt;- as.integer(xc2==4)\n    z5 &lt;- as.integer(xc2==5)\n    mav4 &lt;- rollmean(z4,window)\n    mav5 &lt;- rollmean(z5,window)\n    df &lt;- data.frame(av4=mav4, av5=mav5, x=rep(1:1000, length=length(mav4)),\n                     gp=(0:(length(mav4)-1))%/%1000)\n    print(xyplot(av4+av5 ~ x | gp, data=df, layout=c(1,10), type=\"l\",\n                 par.strip.text=list(cex=0.65)))\n  }\n## Use thus\nlibrary(zoo)  # Use rollmean() [moving average] from zoo\nlibrary(lattice)\nplotmarkov(start=1)\nplotmarkov(start=4)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Answers to Selected Chapter 2 Exercises</span>"
    ]
  },
  {
    "objectID": "ch3.html",
    "href": "ch3.html",
    "title": "3  Answers to Selected Chapter 3 Exercises",
    "section": "",
    "text": "library(DAAG)\n\n\n\nExercise 4\n\nIn the data set cement (MASS package), examine the dependence of y (amount of heat produced) on x1, x2, x3 and x4 (which are proportions of four constituents). Begin by examining the scatterplot matrix. As the explanatory variables are proportions, do they require transformation, perhaps by taking \\(\\log(x/(100-x))\\)? What alternative strategies might be useful for finding an equation for predicting heat?\n\nFirst, obtain the scatterplot matrix for the untransformed cement data:\n\n\n\n\n\n\n\n\nFigure 3.1\n\n\n\n\n\n\ncement &lt;- MASS::cement\npairs(cement, main=\"Scatterplot matrix for the cement data\")\n\nSince the explanatory variables are proportions, a transformation such as that suggested might be helpful, though the bigger issue is the fact that the sum of the explanatory variables is nearly constant, leading to severe multicollinearity as indicated both by the variance inflation factors, and by the strong correlation between x4andx2 that is evident in the scatterplot matrix.\n\ncement.lm &lt;- lm(y ~ x1+x2+x3+x4, data=cement)\nDAAG::vif(cement.lm)\n\n     x1      x2      x3      x4 \n 38.496 254.420  46.868 282.510 \n\n\nWe may wish to include just one of x2andx4. The following omits x4:\n\ncement.lm2 &lt;- lm(y ~ x1+x2+x3, data=cement)\nDAAG::vif(cement.lm2)\n\n    x1     x2     x3 \n3.2511 1.0636 3.1421 \n\n\nThe multicollinearity is less severe. We check the standard diagnostics for the linear model:\n\npar(mfrow=c(1,4))\nplot(cement.lm2)\n\n\n\n\n\n\n\n\nNothing seems amiss on these plots. The three variable model seems satisfactory. Upon looking at the summary, one might argue for removing the variable x3.\nFor the logit analysis, first define the logit function:\n\nlogit &lt;- function(x) log(x/(100-x))\n\nNow form the transformed data frame, and show the scatterplot matrix:\n\nlogitcement &lt;- data.frame(logit(cement[,c(\"x1\",\"x2\",\"x3\",\"x4\")]), \n     y=cement[, \"y\"])\npairs(logitcement)\ntitle(main=\"Scatterplot matrix for the logits of the proportions.\")\n\n\n\n\n\n\n\n\nNotice that the relationship between x2 and x4 is now more nearly linear. This is helpful – it is advantageous for collinearities or multicollinearities to be explicit.\nNow fit the full model, and plot the diagnostics:\n\nlogitcement.lm &lt;- lm(y ~ x1+x2+x3+x4, data=logitcement)\npar(mfrow=c(1,4))\nplot(logitcement.lm)\ntitle(main=\"Diagnostic plots for the model that works with logits\")\n\n\n\n\n\n\n\n\nThe multicollinearity is now less extreme, though still substantial. This happens because some observations now appear as influential outliers. Is it best not to transform the predictors?\n\n\nExercise 6\n\n*The data frame hills2000 in our DAAG package has data, based on information from the Scottish Running Resource web site, that updates the 1984 information in the data set hills. Fit a regression model, for men and women separately, based on the data in hills2000. Check whether it fits satisfactorily over the whole range of race times. Compare the equation that you obtain with that based on the hills data frame.\n\n\nhills2K &lt;- DAAG::hills2000\n\nWe begin with the same kind of transformed model that we tried in Section 3.2.2 for the hills data, examining the diagnostic plots and the termplots.\n\nhills2K.loglm &lt;- lm(log(time) ~ log(dist) + log(climb),\n                    data=hills2K)\npar(mfrow=c(1,4))\nplot(hills2K.loglm)\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\ntermplot(hills2K.loglm, transform.x=T, partial=T)\n\nThe first of the diagnostic plots (residuals versus fitted values) reveals three potential outliers, identified as 12 Trig Trog, Chapelgill, and Caerketton.\nA robust fit, which may be a safer guide, leads to quite similar diagnostic plots and termplots. Simply replace lm() by MASS::rlm() and repeat the plots.\nThe first of the diagnostic plots shows a bucket shaped pattern in the residuals, suggesting that the log(time) is not quite the right transformation of time. The following investigates the use of a power transformation:\n\n\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1   -0.0978        -0.1      -0.1778      -0.0178\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                           LRT df     pval\nLR test, lambda = (0) 5.920789  1 0.014963\n\nLikelihood ratio test that no transformation is needed\n                          LRT df       pval\nLR test, lambda = (1) 238.116  1 &lt; 2.22e-16\n\n\nA power transformation with \\(\\lambda\\) = -0.1 is indicated. This leads to the fitted model ptime.rlm thus:\n\nptime.rlm &lt;- MASS::rlm(car::bcPower(time, -0.1) ~ log(dist) +\n                               log(climb), data=hills2K)\nsummary(ptime.rlm)                               \n\n\nCall: rlm(formula = car::bcPower(time, -0.1) ~ log(dist) + log(climb), \n    data = hills2K)\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.461482 -0.067431 -0.007533  0.077235  0.240752 \n\nCoefficients:\n            Value    Std. Error t value \n(Intercept)  -4.0568   0.1753   -23.1367\nlog(dist)     0.7969   0.0313    25.4924\nlog(climb)    0.3129   0.0284    11.0054\n\nResidual standard error: 0.1058 on 53 degrees of freedom\n\n\nDiagnostic plots are:\n\npar(mfrow=c(1,4))\nplot(ptime.rlm, add.smooth=FALSE)\n\n\n\n\n\n\n\n\nCaerketton now stands out.\nFor putting a smooth through the plot of residuals versus fitted values, one needs to do a robust fit. One can use a ‘loess()’ fit with family=\"symmetric\". A more theoretically informed approach is to use a GAM smooth as described in Chapter 4, with family=\"scat\".\n\nplot(fitted(ptime.rlm), residuals(ptime.rlm))\nres.gam &lt;- mgcv::gam(residuals(ptime.rlm)~s(fitted(ptime.rlm)),  \n                       family='scat')\npoints(fitted(ptime.rlm), fitted(res.gam), col='red')                       \n\n\n\n\n\n\n\n\nNow see how the fitted model fares when applied to the DAAG::hills dataset:\n\nptimehills &lt;- car::bcPower(DAAG::hills$time, lambda=-0.1)\nppredhills &lt;- predict(ptime.rlm, newdata=DAAG::hills)\nplot(ppredhills, ptimehills)\nabline(0,1)\n\n\n\n\n\n\n\n\nThe line shows close agreement with the earlier data. As hills2000 was an update on the earlier hills data, this is not surprising.\nThe steps above should then be repeated for the female records.\n\n\nExercise 7\n\n*Section 3.1 used lm() to analyze the allbacks data that are presented in Figure 3.1. Repeat the analysis using (1) the function rlm() in the MASS package, and (2) the function lqs()} in the MASS package. Compare the two sets of results with the results in Section 3.1.\n\nHere are fits, w/wo intercept, using rlm()\n\nlibrary(MASS)\nallbacks &lt;- DAAG::allbacks\nallbacks.rlm &lt;- rlm(weight ~ volume+area, data=allbacks)\nsummary(allbacks.rlm)\n\n\nCall: rlm(formula = weight ~ volume + area, data = allbacks)\nResiduals:\n    Min      1Q  Median      3Q     Max \n-80.860 -22.182  -9.578  34.540 232.258 \n\nCoefficients:\n            Value   Std. Error t value\n(Intercept)  9.2388 40.3159     0.2292\nvolume       0.7015  0.0422    16.6405\narea         0.5145  0.0704     7.3106\n\nResidual standard error: 39.43 on 12 degrees of freedom\n\nallbacks.rlm0 &lt;- rlm(weight ~ volume+area-1, data=allbacks)\nsummary(allbacks.rlm0)\n\n\nCall: rlm(formula = weight ~ volume + area - 1, data = allbacks)\nResiduals:\n   Min     1Q Median     3Q    Max \n-86.00 -20.57 -10.30  36.13 231.76 \n\nCoefficients:\n       Value   Std. Error t value\nvolume  0.7111  0.0185    38.5110\narea    0.5168  0.0624     8.2877\n\nResidual standard error: 39.7 on 13 degrees of freedom\n\n\nHere are plots of residuals against fitted values, for the two models.\n\n\n\n\n\n\n\n\nFigure 3.2\n\n\n\n\n\nCode is:\n\npar(mfrow=c(1,2))\nplot(allbacks.rlm, which=1)   # residual plot\nmtext(side=3, line=1, \"rlm(), intercept included\")\nplot(allbacks.rlm0, which=1)  # residual plot\nmtext(side=3, line=1, \"rlm(), no intercept\")\n\nComparison of the coefficients of the intercept and no-intercept with the lm() counterparts reveals larger differences in coefficient estimates for the intercept models. The robust method has given smaller coefficient standard errors than lm().\nThe influence of the outlying observation (the 13th) is reduced using the robust method; therefore, on the residual plots we see this observation featured even more prominently as an outlier than on the corresponding plots for the lm() fits.\nWe next consider the lqs() approach. By default, lqs() employs a resistant regression method called least trimmed squares regression (lts), an idea due to Rousseeuw (1984) (“Least median of squares regression.” Journal of the American Statistical Association 79: 871–888). The method minimizes the sum of the \\(k\\) smallest squared residuals, where \\(k\\) is usually taken to be slightly larger than 50% of the sample size. This approach removes all of the influence of outliers on the fitted regression line.\n\nallbacks.lqs &lt;- lqs(weight ~ volume+area, data=allbacks)\nallbacks.lqs$coefficients  # intercept model\n\n(Intercept)      volume        area \n-59.6232046   0.7736944   0.4709100 \n\nallbacks.lqs0 &lt;- lqs(weight ~ volume+area-1, data=allbacks)\ncoefficients(allbacks.lqs0)  # no-intercept model\n\n   volume      area \n0.7116612 0.4849406 \n\n\nThe robust coefficient estimates of volume and area are similar to the corresponding coefficient estimates for the lm() fit.\nHere are plots of residuals against fitted values, for the two models.\n\n\n\n\n\n\n\n\n\nBecause the outlying observation (13) is now not used at all in the final regression coefficient estimates, it has no influence. Neither does observation 11, another outlier. Both points plot farther away from the reference line at 0 than in the corresponding lm() residual plots.\n\n\nExercise 9\n\n*Fit the model brainwt ~ bodywt + lsize to the litters dataset, then checking the variance inflation factors for bodywt and for lsize. Comment.\n\nWe can use the function vif() to determine the variance inflation factors for the litters data as follows: {r ex9, echo=TRUE} litters &lt;- DAAG::litters litters.lm &lt;- lm(brainwt ~ bodywt + lsize, data=litters) DAAG::vif(litters.lm) %\nA scatterplot of litter size versus body weight would confirm that the two variables have a relation which is close to linear. The effect is to give inflated standard errors in the above regression, though not enough to obscure the relationship between brain weight and body weight and litter size completely.\nIt is hazardous to make predictions of brain weight for pigs having body weight and litter size which do not lie close to the line relating these variables.\n\n\nExercise 12\n\nThe data frame MPV::table.b3 has data on gas mileage and eleven other variables for a sample of 32 automobiles.\n. Construct a scatterplot of y (mpg) versus x1 (displacement). Is the relationship between these variables nonlinear? - Use the xyplot() function, and x11 (type of transmission) as a group variable. Is a linear model reasonable for these data?\nb. Fit the model, relating y to x1 and x11, which gives two lines having possibly different gradients and intercepts. Check the diagnostics. Are there any influential observations? Are there any influential outliers?\nc. Plot the residuals against the variable x7 (number of transmission speeds), again using x11 as a group variable. Comment on anything unusual about this plot?\n\n\nSee Panel A in the graph that follows The scatterplot suggests a curvilinear relationship.\n\nSee Panel B in the graph that follows. This suggests that the apparent nonlinearity is better explained by the two types of transmission.\n\n\nlibrary(lattice)\n## Panel A \ngph1 &lt;- xyplot(y ~ x1, data=MPV::table.b3) \n## Panel B\nlibrary(lattice) \ngph2 &lt;- xyplot(y ~ x1, group=x11, data=MPV::table.b3) \nc('A: Plot y vs x1'=gph1, 'B: Group by transmission type'=gph2, layout=c(2,1))\n\n\n\n\n\n\n\n\n\n\n\n\n b3.lm &lt;- lm(y ~ x1*x11, data=MPV::table.b3)\n par(mfrow=c(1,4), pty=\"s\")\n plot(b3.lm)\n\n\n\n\n\n\n\n\nObservation 5 is influential, but it is not an outlier.\nd.\n\nxyplot(resid(b3.lm) ~ x7, groups=x11, data=MPV::table.b3, fig.aspect=1, out.width=\"50%\")\n\n\n\n\n\n\n\n\nThis plot demonstrates that observation 5 is quite special. It is based on the only car in the data set with a 3-speed manual transmission.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Answers to Selected Chapter 3 Exercises</span>"
    ]
  },
  {
    "objectID": "ch4.html",
    "href": "ch4.html",
    "title": "4  Answers to Selected Chapter 4 Exercises",
    "section": "",
    "text": "output: html_document: default pdf_document: includes: in_header: “preamble.tex” latex_engine: xelatex\n\n\n\n\n\nlibrary(DAAG)\n\n\n\nExercise 1\n\nRe-analyze the sugar weight data of Subsection 4.1.1 using the log(weight) in place of weight.\n\nFrom the scatterplot in Figure 4.1, it is clear that the treatment variances are not constant. Perhaps a logarithmic transformation will stabilize the variances.\n\nsugarlog.aov &lt;- aov(log(weight) ~ trt, data=sugar)\nsummary.lm(sugarlog.aov)\n\n\nCall:\naov(formula = log(weight) ~ trt, data = sugar)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.165171 -0.043725 -0.002533  0.039628  0.170688 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  4.41224    0.05738  76.900 9.11e-13\ntrtA        -0.29015    0.08114  -3.576  0.00723\ntrtB        -0.20109    0.08114  -2.478  0.03822\ntrtC        -0.52291    0.08114  -6.444  0.00020\n\nResidual standard error: 0.09938 on 8 degrees of freedom\nMultiple R-squared:  0.8426,    Adjusted R-squared:  0.7835 \nF-statistic: 14.27 on 3 and 8 DF,  p-value: 0.001414\n\nsummary.lm(sugarlog.aov)\n\n\nCall:\naov(formula = log(weight) ~ trt, data = sugar)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.165171 -0.043725 -0.002533  0.039628  0.170688 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  4.41224    0.05738  76.900 9.11e-13\ntrtA        -0.29015    0.08114  -3.576  0.00723\ntrtB        -0.20109    0.08114  -2.478  0.03822\ntrtC        -0.52291    0.08114  -6.444  0.00020\n\nResidual standard error: 0.09938 on 8 degrees of freedom\nMultiple R-squared:  0.8426,    Adjusted R-squared:  0.7835 \nF-statistic: 14.27 on 3 and 8 DF,  p-value: 0.001414\n\n\nOn the log scale, the differences from control remain discernible. However the plot should be compared with plots from random normal data. This should be repeated several times. There will be occasional samples that show changes in variability of the observed residuals that are of the extent observed for these data.\nTHe following shows plots of residuals versus fitted values, for the log(sugar weight) data, and for random normal data.\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,3))\nplot(sugarlog.aov, which=1, caption=\"Sugar data\")\nfor(i in 1:5){\n    plot(aov(rnorm(12)~sugar$trt), which=1, caption=\"Random normal data\")\n    title(main=, line=1.75)\n}\n\n\n\nExercise 3\n\nFor each of the datasets DAAG::elastic1 and DAAG::elastic2, determine the egression of stretch on distance. Use the method of Section 4.3 to compare, formally, the two regression lines.\n\nIt will be convenient to work with a single data frame:\n\nelastic2$expt &lt;- rep(2, length(elastic2$stretch))\nelastic1$expt &lt;- rep(1, length(elastic1$stretch))\nelastic &lt;- rbind(elastic1, elastic2)\nelastic$expt &lt;- factor(elastic$expt)\n\nWe fit two models as follows:\n\ne.lm1 &lt;- lm(distance ~ stretch, data=elastic)    # a single line\ne.lm2 &lt;- lm(distance ~ stretch + expt, data=elastic)  \n  # two parallel lines\ne.lm3 &lt;- lm(distance ~ stretch + expt + stretch:expt, data=elastic)\n  # two lines\n\nThe following sequential analysis of variance table indicates that there is mild evidence against the two lines having the same intercept.\n\nanova(e.lm1, e.lm2, e.lm3)\n\nAnalysis of Variance Table\n\nModel 1: distance ~ stretch\nModel 2: distance ~ stretch + expt\nModel 3: distance ~ stretch + expt + stretch:expt\n  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)\n1     14 2549.0                            \n2     13 2017.4  1    531.61 3.2249 0.09773\n3     12 1978.1  1     39.25 0.2381 0.63435\n\n\nA check will show that observation 7 is an influential outlier. Let’s check to see what happens to the three models when this observation is deleted.\n\ne.lm1 &lt;- lm(distance ~ stretch, data=elastic[-7,])\ne.lm2 &lt;- lm(distance ~ stretch + expt, data=elastic[-7,])\ne.lm3 &lt;- lm(distance ~ stretch + expt + stretch:expt, data=elastic[-7,])\nanova(e.lm1, e.lm2, e.lm3)\n\nAnalysis of Variance Table\n\nModel 1: distance ~ stretch\nModel 2: distance ~ stretch + expt\nModel 3: distance ~ stretch + expt + stretch:expt\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1     13 1204.9                           \n2     12 1042.4  1   162.496 1.7870 0.2083\n3     11 1000.2  1    42.156 0.4636 0.5100\n\n\nNow, we see that there is really very little evidence of a difference between the two lines. Observation 7 seems different in character from other observations.\n\n\nExercise 4\n\nThe data frame toycars consists of 27 observations on the distance (in meters) traveled by one of three different toy cars on a smooth surface, starting from rest at the top of a16-inch-long ramp tilted at varying angles (measured in degrees). Because of differing frictional effects for the three different cars, we seek three regression lines relating distance traveled to angle (measured in degrees). Start by plotting the data:\n\ntoycars &lt;- DAAG::toycars\nlattice ::xyplot(distance ~ angle, groups=factor(car), type=c('p','r'),\n                 data=toycars, auto.key=list(columns=3))\n\n\nFit the following models:\n\n\nparLines.lm &lt;- lm(distance ~ 0+factor(car)+angle, data=toycars)\nsepLines.lm &lt;- lm(distance ~ factor(car)/angle, data=toycars)\n\nCompare the AIC statistics for the two models. Examine the diagnostic plots carefully. Is there a systematic pattern of departure from linear relationships?\nb. Fit the model\n\nsepPol3.lm &lt;- lm(distance ~ factor(car)/angle+poly(angle,3)[,2:3], data=toycars)\n\nCompare the AIC statistics with those for the two models that fitted straight line relationships. Compare the diagnostic plots, with the diagnostic plots for one or other of the straight line models.\nc. Repeat the comparison using the code:\n\nsapply(list(parLines.lm, sepLines.lm, sepPol3.lm), AICcmodavg::AICc)\n\nComment on the result.\nd. A plausible physical model suggests that the three lines should have the same intercept (close to 0), and possibly differing slopes, where the slopes are inversely related to the coefficient of dynamic friction for each car. Is that consistent from what is apparent here? Comment.\ne. Extract the adjusted \\(R^2\\) statistics for the three models\n\nsetNames(sapply(list(parLines.lm, sepLines.lm, sepPol3.lm),\n  function(x)summary(x)$adj.r.squared), c(\"parLines\",\"sepLines\",\"sepPol3\"))\n\nRepeat for \\(R^2\\). This illustrates why neither of these statistics should be taken too seriously. In neither case does maximizing the statistic give the best model!\n\n\ntoycars$car &lt;- factor(toycars$car)  # car should be a factor\ntoycars.lm &lt;- lm(distance ~ angle + car, data=toycars)\nsummary(toycars.lm)\n\n\nCall:\nlm(formula = distance ~ angle + car, data = toycars)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.098113 -0.042401 -0.006689  0.017408  0.172513 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.092524   0.034671   2.669  0.01372\nangle        0.188541   0.009945  18.958 1.55e-15\ncar2         0.111111   0.031951   3.478  0.00204\ncar3        -0.082222   0.031951  -2.573  0.01699\n\nResidual standard error: 0.06778 on 23 degrees of freedom\nMultiple R-squared:  0.9451,    Adjusted R-squared:  0.938 \nF-statistic: 132.1 on 3 and 23 DF,  p-value: 1.219e-14\n\n\nFrom the diagnostics (below), we see that there is an influential outlier. The model is not fitting all of the data satisfactorily.\n\n\n\n\n\n\n\n\n\nCode is:\n\npar(mfrow=c(1,4))\nplot(toycars.lm)\n\nTo fit the model with a constant intercept and possibly differing slopes, we proceed as follows:\n\ntoycars.lm2 &lt;- lm(distance ~ angle + angle:car, data=toycars)\nsummary(toycars.lm2)\n\n\nCall:\nlm(formula = distance ~ angle + angle:car, data = toycars)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.10841 -0.04678 -0.01225  0.06970  0.10618 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.10215    0.03037   3.364  0.00268\nangle        0.18190    0.01215  14.971 2.38e-13\nangle:car2   0.04158    0.01120   3.714  0.00114\nangle:car3  -0.02167    0.01120  -1.935  0.06539\n\nResidual standard error: 0.07011 on 23 degrees of freedom\nMultiple R-squared:  0.9413,    Adjusted R-squared:  0.9336 \nF-statistic: 122.9 on 3 and 23 DF,  p-value: 2.653e-14\n\n\nWe can see from the diagnostics below that observation 17 is still somewhat influential, but it is no longer an outlier. All of the data are accommodated by this new model reasonably well.\n\n\n\n\n\n\n\n\n\n\n\nExercise 5\n\nThe data frame cuckoos holds data on the lengths and breadths of eggs of cuckoos, found in the nests of six different species of host birds. Fit models for the regression of length on breadth that have:\na. a single line for all six species.\nb. different parallel lines for the different host species.\nc. separate lines for the separate host species. \nUse the anova() function to print out the sequential analysis of variance table. Which of the three models is preferred? Print out the diagnostic plots for this model. Do they show anything worthy of note? Examine the output coefficients from this model carefully, and decide whether the results seem grouped by host species. How might the results be summarized for reporting purposes?\n\n\ncuckoos.lm &lt;- lm(length ~ breadth, data=cuckoos)  # one line\ncuckoos.lm2 &lt;- lm(length ~ breadth + species, data=cuckoos) \n                                 # parallel lines\ncuckoos.lm3 &lt;- lm(length ~ breadth + species + species:breadth, \n                  data=cuckoos)  # different lines\n\nanova(cuckoos.lm, cuckoos.lm2, cuckoos.lm3)\n\nAnalysis of Variance Table\n\nModel 1: length ~ breadth\nModel 2: length ~ breadth + species\nModel 3: length ~ breadth + species + species:breadth\n  Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)\n1    118 101.923                              \n2    113  79.114  5   22.8096 6.5711 2.244e-05\n3    108  74.978  5    4.1356 1.1914    0.3182\n\n\nThe anova summary shows a preference for the second mode. The standard diagnostics are given below.\n\n\n\n\n\n\n\n\n\nThere is nothing on these plots that calls for especial attention.\n\nsummary(cuckoos.lm2)\n\n\nCall:\nlm(formula = length ~ breadth + species, data = cuckoos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.37337 -0.49106 -0.06816  0.52980  2.54470 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)          9.51559    3.01765   3.153 0.002068\nbreadth              0.81117    0.17951   4.519 1.54e-05\nspeciesmeadow.pipit -0.80125    0.25610  -3.129 0.002234\nspeciespied.wagtail -0.01324    0.31454  -0.042 0.966503\nspeciesrobin        -0.30310    0.31137  -0.973 0.332414\nspeciestree.pipit    0.04490    0.31143   0.144 0.885621\nspecieswren         -1.23912    0.35300  -3.510 0.000644\n\nResidual standard error: 0.8367 on 113 degrees of freedom\nMultiple R-squared:  0.4192,    Adjusted R-squared:  0.3884 \nF-statistic: 13.59 on 6 and 113 DF,  p-value: 1.439e-11\n\n\nThe baseline species is hedge sparrow, and we see some groupings among the host species.\nThe relation between length and breadth of the eggs is similar when the\nhost species are hedge sparrow, pied wagtail and tree pipit. Even when the robin is the host species, there is little evidence of a difference in the way in which length and breadth are related. However, the linear relation between length and breadth has a smaller intercept when the host species is either the meadow pipit or the wren.\n\n\nExercise 7\n\n*Compare the two results\n\nseedrates.lm &lt;- lm(grain ~ rate + I(rate^2), data=seedrates)\nseedrates.pol &lt;- lm(grain ~ poly(rate,2), data=seedrates)\n\nCheck that the fitted values and residuals from the two calculations are the same, and that the \\(t\\)-statistic and \\(p\\)-value are the same for the final coefficient, i.e., the same for the coefficient labeled poly(rate, 2)2 in the polynomial regression as for the coefficient labeled I(rate^2) in the regression on rate and rate^2.\nRegress the second column of model.matrix(seedrates.pol) on rate and I(rate^2), and similarly for the third column of model.matrix(seedrates.pol). Hence express the first and second orthogonal polynomial terms as functions of rate and rate^2.\n\nThe following shows that the fitted values and residuals are the same for the two calculations. The \\(t\\)-statistic and \\(p\\)-value are also the same for the final coefficient.\n\nseedrates.lm &lt;- lm(grain ~ rate + I(rate^2), data=seedrates)\nseedrates.pol&lt;- lm(grain ~ poly(rate, 2), data=seedrates)\nfitted(seedrates.lm)-fitted(seedrates.pol)\n\n1 2 3 4 5 \n0 0 0 0 0 \n\nresid(seedrates.lm)-resid(seedrates.pol)\n\n            1             2             3             4             5 \n-3.122502e-16  5.967449e-16 -9.714451e-17 -3.035766e-16  1.543904e-16 \n\nsummary(seedrates.lm)\n\n\nCall:\nlm(formula = grain ~ rate + I(rate^2), data = seedrates)\n\nResiduals:\n        1         2         3         4         5 \n 0.045714 -0.122857  0.094286 -0.002857 -0.014286 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  2.406e+01  4.557e-01  52.799 0.000359\nrate        -6.669e-02  9.911e-03  -6.728 0.021384\nI(rate^2)    1.714e-04  4.902e-05   3.497 0.072943\n\nResidual standard error: 0.1146 on 2 degrees of freedom\nMultiple R-squared:  0.9961,    Adjusted R-squared:  0.9922 \nF-statistic: 255.7 on 2 and 2 DF,  p-value: 0.003895\n\nsummary(seedrates.pol)\n\n\nCall:\nlm(formula = grain ~ poly(rate, 2), data = seedrates)\n\nResiduals:\n        1         2         3         4         5 \n 0.045714 -0.122857  0.094286 -0.002857 -0.014286 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    19.32000    0.05127 376.832 7.04e-06\npoly(rate, 2)1 -2.56144    0.11464 -22.343   0.0020\npoly(rate, 2)2  0.40089    0.11464   3.497   0.0729\n\nResidual standard error: 0.1146 on 2 degrees of freedom\nMultiple R-squared:  0.9961,    Adjusted R-squared:  0.9922 \nF-statistic: 255.7 on 2 and 2 DF,  p-value: 0.003895\n\n\nFrom the following output, we can infer that the first orthogonal polynomial is \\[ p_1(x) = -1.265 + .01265x\n\\] and the second orthogonal polynomial is \\[ p_2(x) = 3.742 - .08552x + .0004276x^2\\]\n\nattach(seedrates)\ny &lt;- model.matrix(seedrates.pol)[,2]\ny.lm &lt;- lm(y ~ rate + I(rate^2))\ncoef(y.lm)\n\n  (Intercept)          rate     I(rate^2) \n-1.264911e+00  1.264911e-02  8.036035e-20 \n\ny &lt;- model.matrix(seedrates.pol)[,3]\ny.lm &lt;- lm(y ~ rate + I(rate^2))\ncoef(y.lm)\n\n (Intercept)         rate    I(rate^2) \n 3.741657387 -0.085523597  0.000427618 \n\n\nAmong other things, the polynomials given above have the property that \\[\np_1(50)p_2(50) + p_1(75)p_2(75) + p_1(100)p_2(100)+p_1(125)p_2(125)+\np_1(150)p_2(150)\n\\] since the values of the predictor are:\n\nrate\n\n[1]  50  75 100 125 150\n\ndetach(seedrates)\n\n\n\nExercise 14\n\nThe ozone data frame holds data, for nine months only, on ozone levels at the Halley Bay station between 1956 and 2000. (See Christie (2000) and Shanklin (2001) for the scientific background. Up to date data are available from the website given under ?DAAG::ozone. Replace zeros by missing values. Determine, for each month, the number of missing values. Plot the October levels against Year, and fit a smooth curve. At what point does there seem to be clear evidence of a decline? Plot the data for other months also. Do other months show a similar pattern of decline?\n\nA simple way to replace 0’s by missing value codes is the following: ::: {.cell layout-align=“center”}\nnames(ozone)\n\n [1] \"Year\"   \"Aug\"    \"Sep\"    \"Oct\"    \"Nov\"    \"Dec\"    \"Jan\"    \"Feb\"   \n [9] \"Mar\"    \"Apr\"    \"Annual\"\n\nOzone &lt;- ozone\nfor (i in 2:11){\n    Ozone[ozone[,i]==0, i] &lt;- NA\n}\n:::\nOne way to count up the monthly missing values is the following: ::: {.cell layout-align=“center”}\nsapply(Ozone[,-c(1,11)], function(x) sum(is.na(x)))\n\nAug Sep Oct Nov Dec Jan Feb Mar Apr \n 21   8   0   0   0   0   0   0  11 \n\n:::\nA plot of the October ozone levels against Year can be obtained as follows: ::: {.cell layout-align=“center”} ::: {.cell-output-display}  ::: :::\nWe see that ozone level is decreasing throughout the period, but there is an acceleration in the mid- to late-1970s.\nTo plot the data for the other months, we can do the following:\n\n\n\n\n\n\n\n\n\nSimilar declines are evident in several of the other months. The decline is less steep in some of the other months.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Answers to Selected Chapter 4 Exercises</span>"
    ]
  },
  {
    "objectID": "ch5.html",
    "href": "ch5.html",
    "title": "5  Answers to Selected Chapter 5 Exercises",
    "section": "",
    "text": "Exercise 1\n\nThe following table shows numbers of occasions when inhibition (i.e., no flow of current across a membrane) occurred within 120 s, for different concentrations of the protein peptide-C (data are used with the permission of Claudia Haarmann, who obtained these data in the course of her PhD research). The outcome yes implies that inhibition has occurred.\nconc 0.1 0.5  1 10 20 30 50 70 80 100 150\nno     7   1 10  9  2  9 13  1  1   4   3\nyes    0   0  3  4  0  6  7  0  0   1   7\nUse logistic regression to model the probability of inhibition as a function of protein concentration.\n\nIt is useful to begin by plotting the logit of the observed proportions against log(conc). Concentrations are nearer to equally spaced on a scale of relative dose, rather than on a scale of dose, suggesting that it might be appropriate to work with log(conc). In order to allow plotting of cases where no = 0 or yes = 0, we add 0.5 to each count.\n\n\n\n\n\n\n\n\n\nThe plot seems reasonably consistent with the use of log(conc) as the explanatory variable. Code is:\n\nconc &lt;- c(.1, .5, 1, 10, 20, 30, 50, 70, 80, 100, 150)\nno &lt;- c(7, 1, 10, 9, 2, 9, 13, 1, 1, 4, 3)\nyes &lt;- c(0, 0, 3, 4, 0, 6, 7, 0, 0, 1 ,7)\nn &lt;- no + yes\nplot(log(conc), log((yes+0.5)/(no+0.5)))\n\nThe code for the regression is: p &lt;- yes/n inhibit.glm &lt;- glm(p ~ I(log(conc)), family=binomial, weights=n) summary(inhibit.glm)\n\n::: {.colbox data-latex=\"\"}\n::: {data-latex=\"\"}\nExercise 2\n:::\nIn the data set (an artificial one of 3121 patients, that is\n  similar to a subset of the data analyzed in Stiell et al. (2001))\n  `minor.headInjury`, obtain a logistic\n  regression model relating\n  `clinically.important.brain.injury`  to other variables.  \nPatients whose risk is sufficiently high will be sent for CT\n(computed tomography). Using a risk threshold of 0.025 (2.5\\%),\nturn the result into a decision rule for use of CT.\n:::\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsapply(headInjury, range)\n\n     age.65 amnesia.before basal.skull.fracture GCS.decrease GCS.13\n[1,]      0              0                    0            0      0\n[2,]      1              1                    1            1      1\n     GCS.15.2hours high.risk loss.of.consciousness open.skull.fracture vomiting\n[1,]             0         0                     0                   0        0\n[2,]             1         1                     1                   1        1\n     clinically.important.brain.injury\n[1,]                                 0\n[2,]                                 1\n\ninjury.glm &lt;- glm(clinically.important.brain.injury ~ ., \n                  data=headInjury, family=binomial)\nsummary(injury.glm)\n\n\nCall:\nglm(formula = clinically.important.brain.injury ~ ., family = binomial, \n    data = headInjury)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)            -4.4972     0.1629 -27.611  &lt; 2e-16\nage.65                  1.3734     0.1827   7.518 5.56e-14\namnesia.before          0.6893     0.1725   3.996 6.45e-05\nbasal.skull.fracture    1.9620     0.2064   9.504  &lt; 2e-16\nGCS.decrease           -0.2688     0.3680  -0.730 0.465152\nGCS.13                  1.0613     0.2820   3.764 0.000168\nGCS.15.2hours           1.9408     0.1663  11.669  &lt; 2e-16\nhigh.risk               1.1115     0.1591   6.984 2.86e-12\nloss.of.consciousness   0.9554     0.1959   4.877 1.08e-06\nopen.skull.fracture     0.6304     0.3151   2.001 0.045424\nvomiting                1.2334     0.1961   6.290 3.17e-10\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1741.6  on 3120  degrees of freedom\nResidual deviance: 1201.3  on 3110  degrees of freedom\nAIC: 1223.3\n\nNumber of Fisher Scoring iterations: 6\n\n:::\nObserve that log(.025/(1-.025)) = -3.66, an increase of 0.84 above the intercept (= -4.50). This change in risk results from (1) GCS.decrease with any other individual factor except amnesia.before, GCS.decrease and open.skull.fracture; (2) GCS.decrease with any two of amnesia.before, open.skull.fracture and loss.of.consciousness; (3) any of the individual factors age.65, basal.skull.fracture, GCS.15.2hours, high.risk and vomiting, irrespective of the levels of other factors.\n\n\nExercise 3\n\nConsider again the moths data set of Subsection 5.4.2.\n\nWhat happens to the standard error estimates when the poisson family is used in glm() instead of the quasipoisson family?\nAnalyze the P moths, in the same way as the A moths were analyzed. Comment on the effect of transect length.\n\n\n\nThe dispersion estimate was 2.7. Use of the quasipoisson family has the effect of increasing SEs by a factor of \\(\\sqrt{2.7}\\), relative to the poisson family. SEs on pp.265 will thus be reduced by this factor if the poisson family is (inappropriately) specified.\n\n\n\n\nsapply(split(moths$P, moths$habitat), sum)\n\n     Bank Disturbed Lowerside    NEsoak    NWsoak    SEsoak    SWsoak Upperside \n        4        33        17        14        19         6        48         8 \n\nmoths$habitat &lt;- relevel(moths$habitat, ref=\"Lowerside\")\nP.glm &lt;- glm(P ~ habitat + log(meters), family=quasipoisson, \n             data=moths)\n\nThe highest numbers are now for SWsoak and for Disturbed The number of moths increases with transect length, by a factor of approximately 1.74 (= \\(e^.55\\)) for each one meter increase in transect length. \\end{enumerate} ````\n\n\nExercise 4\n\n*The factor dead in the data set mifem (DAAG package) gives the mortality outcomes (live or dead), for 1295 female subjects who suffered a myocardial infarction. (See Subsection 8.3.1 for further details.) Determine ranges for age and yronset (year of onset), and determine tables of counts for each separate factor. Decide how to handle cases for which the outome, for one or more factors, is not known. Fit a logistic regression model, beginning by comparing the model that includes all two-factor interactions with the model that has main effects only.\n\nFirst, examine various summary information:\n\nstr(mifem)\n\n'data.frame':   1295 obs. of  10 variables:\n $ outcome : Factor w/ 2 levels \"live\",\"dead\": 1 1 1 1 2 1 1 2 2 2 ...\n $ age     : num  63 55 68 64 67 66 63 68 46 66 ...\n $ yronset : num  85 85 85 85 85 85 85 85 85 85 ...\n $ premi   : Factor w/ 3 levels \"y\",\"n\",\"nk\": 2 2 1 2 2 2 2 1 2 1 ...\n $ smstat  : Factor w/ 4 levels \"c\",\"x\",\"n\",\"nk\": 2 1 4 2 4 2 3 3 1 1 ...\n $ diabetes: Factor w/ 3 levels \"y\",\"n\",\"nk\": 2 2 3 2 3 3 2 2 2 2 ...\n $ highbp  : Factor w/ 3 levels \"y\",\"n\",\"nk\": 1 1 1 1 3 3 1 1 1 1 ...\n $ hichol  : Factor w/ 3 levels \"y\",\"n\",\"nk\": 1 1 3 2 3 3 2 1 3 2 ...\n $ angina  : Factor w/ 3 levels \"y\",\"n\",\"nk\": 2 2 1 1 3 3 2 1 3 2 ...\n $ stroke  : Factor w/ 3 levels \"y\",\"n\",\"nk\": 2 2 2 2 3 3 2 1 2 1 ...\n\nsapply(mifem[, c(\"age\", \"yronset\")], range)\n\n     age yronset\n[1,]  35      85\n[2,]  69      93\n\nlapply(mifem[, -(1:3)], table)\n\n$premi\n\n  y   n  nk \n311 928  56 \n\n$smstat\n\n  c   x   n  nk \n390 280 522 103 \n\n$diabetes\n\n  y   n  nk \n248 978  69 \n\n$highbp\n\n  y   n  nk \n813 406  76 \n\n$hichol\n\n  y   n  nk \n452 655 188 \n\n$angina\n\n  y   n  nk \n472 724  99 \n\n$stroke\n\n   y    n   nk \n 153 1063   79 \n\n\nFor all of the factors, there are a large number of nk’s, i.e., not known. A straightforward way to handle them is to treat nk as a factor level that, as for y and n, may give information that helps predict the outcome. For ease of interpretation we will make n, the reference level.\n\nfor(j in 4:10)mifem[,j] &lt;- relevel(mifem[,j], ref=\"n\")\nmifem1.glm &lt;- glm(outcome ~ ., family=binomial, data=mifem)\nmifem2.glm &lt;- glm(outcome ~ .^2, family=binomial, data=mifem)\nanova(mifem1.glm, mifem2.glm)\n\nAnalysis of Deviance Table\n\nModel 1: outcome ~ age + yronset + premi + smstat + diabetes + highbp + \n    hichol + angina + stroke\nModel 2: outcome ~ (age + yronset + premi + smstat + diabetes + highbp + \n    hichol + angina + stroke)^2\n  Resid. Df Resid. Dev  Df Deviance\n1      1277     1172.6             \n2      1152     1013.8 125   158.87\n\nCVbinary(mifem1.glm)\n\n\nFold:  7 9 2 5 1 10 8 4 3 6\nInternal estimate of accuracy = 0.807\nCross-validation estimate of accuracy = 0.803\n\nCVbinary(mifem2.glm)\n\n\nFold:  10 6 8 4 3 1 7 2 5 9\nInternal estimate of accuracy = 0.839\nCross-validation estimate of accuracy = 0.791\n\n\nWarning messages that “fitted probabilities numerically 0 or 1 occurred” have been suppressed in the output shown.\nThe difference in deviance suggests a real difference (pchisq(125,159) = 0.021). Here, however, the chi-squared approximation to the change in deviance should be queried.\nIt is safer to compare the cross-validated accuracy estimates, which in individual cross-validation runs were marginally lower for mifem2.glm than for mifem2.glm; 0.78 as against 0.80. Note also that there were convergence problems for the model that included all first order interaction terms.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Answers to Selected Chapter 5 Exercises</span>"
    ]
  },
  {
    "objectID": "ch6.html",
    "href": "ch6.html",
    "title": "6  Answers to Selected Chapter 6 Exercises",
    "section": "",
    "text": "library(DAAG)\n\n\n\nExercise 1\n\nA time series of length 100 is obtained from an AR(1) model with \\(\\sigma = 1\\) and \\(\\alpha = -.5\\). What is the standard error of the mean? If the usual \\(\\sigma/\\sqrt{n}\\) formula were used in constructing a confidence interval for the mean, with \\(\\sigma\\) defined as in Section 6.1.4, would it be too narrow or too wide?\n\nIf we know \\(\\sigma\\), then the usual \\(\\sigma/\\sqrt{n}\\) formula will give an error that is too narrow; refer back to Subsection 6.1.4. ::: The need to estimate \\(\\sigma\\) raises an additional complication. If \\(\\sigma\\) is estimated by fitting a time series model, e.g., using the function , this estimate of \\(\\sigma\\) can be plugged into the formula in Subsection 9.1.3. The note that now follows covers the case where \\(\\sigma^2\\) is estimated using the formula \\[\\hat{\\sigma^2} = \\frac{\\sum(X_i-\\bar{X})^2}{n-1}\\] The relevant theoretical results are not given in the text. Their derivation requires a kmowledge of the algebra of expectations.\nNote 1: We use the result (proved below) \\[\nE[(X_i-\\mu)^2] = \\sigma^2/(1-\\alpha^2)\n\\] and that \\[\nE[\\sum(X_i-\\bar{X})^2] = \\frac{1}{1-\\alpha^2}(n-1-\\alpha)\\sigma^2\\\\\n\\simeq \\frac{1}{1-\\alpha^2}(n-1)\\sigma^2\n\\] Hence, if the variance is estimated from the usual formula \\(\\hat{\\sigma^2} = \\frac{\\sum(X_i-\\bar{X})^2}{n-1}\\), the standard error of the mean will be too small by a factor of approximately \\[\\sqrt{\\frac{1-\\alpha}{1+\\alpha}}\\].\nNote 2: We square both sides of \\[ X_t - \\mu = \\alpha (X_{t-1} - \\mu) + \\varepsilon_t\\] and take expectations. We have that \\[\nE[(X_t - \\mu)^2] = (1-\\alpha^2)E[(X_t - \\mu)^2] + \\sigma^2\n\\] from which the result (eq.@ref(eq1)) follows immediately. To derive \\(E[\\sum(X_i-\\bar{X})^2]\\), observe that \\[\nE[\\sum(X_i-\\bar{X})^2] = E[(X_t - \\mu)^2] - n(\\bar{X}-\\mu)^2\\]\n\n\nExercise 2\n\nUse the ar function to fit the second order autoregressive model to the Lake Huron time series.\n\n\nar(LakeHuron, order.max=2)\n\n\nCall:\nar(x = LakeHuron, order.max = 2)\n\nCoefficients:\n      1        2  \n 1.0538  -0.2668  \n\nOrder selected 2  sigma^2 estimated as  0.5075\n\n\nIt might however be better not to specify the order, instead allowing the function to choose it, based on the AIC criterion. For this to be valid, it is best to specify also . Fitting by maximum likelihood can for long series be very slow. It works well in this instance.\n\nar(LakeHuron, method=\"mle\")\n\n\nCall:\nar(x = LakeHuron, method = \"mle\")\n\nCoefficients:\n      1        2  \n 1.0437  -0.2496  \n\nOrder selected 2  sigma^2 estimated as  0.4788\n\n\nThe AIC criterion chooses the order equal to 2.\n\n\nExercise 3\n\nRepeat the analysis of Section 6.2, replacing mdbrain by: (i) southRain, i.e., annual average rainfall in Southern Australia; (ii) northRain, i.e., annual average rainfall in Northern Australia.\n\nThe following functions may be used to automate these calculations. First, here is a function that gives the time series plots. {r bomts} bomts &lt;- function(rain=\"NTrain\"){ plot(ts(bomsoi[, c(rain, \"SOI\")], start=1900),        panel=function(y,...)panel.smooth(bomsoi$Year, y,...)) } %\nNext, here is a function that automates the calculations and resulting plots, for the analysis used for all-Australian rainfall data. The parameter choices may for some areas need to be varied, but output from this function should be a good start.\n\nbomplots &lt;-\nfunction(loc=\"NTrain\"){\noldpar &lt;- par(fig=c(0,0.5,0.5,1), mar=c(3.6,3.6,1.6,0.6), mgp=c(2.25,.5,0))\n    on.exit(par(oldpar))\n    rain &lt;- bomsoi[, loc]\n    xbomsoi &lt;-\n      with(bomsoi, data.frame(SOI=SOI, cuberootRain=rain^0.33))\n    xbomsoi$trendSOI &lt;- lowess(xbomsoi$SOI)$y\n    xbomsoi$trendRain &lt;- lowess(xbomsoi$cuberootRain)$y\n    rainpos &lt;- pretty(rain, 5)\n   par(fig=c(0,0.5,0.5,1), new=TRUE)\n    with(xbomsoi,\n         {plot(cuberootRain ~ SOI, xlab = \"SOI\",\n               ylab = \"Rainfall (cube root scale)\", yaxt=\"n\")\n          axis(2, at = rainpos^0.33, labels=paste(rainpos))\n          ## Relative changes in the two trend curves\n          lines(lowess(cuberootRain ~ SOI))\n          lines(lowess(trendRain ~ trendSOI), lwd=2, col=\"gray40\")\n        })\n    xbomsoi$detrendRain &lt;-\n      with(xbomsoi, cuberootRain - trendRain + mean(trendRain))\n    xbomsoi$detrendSOI &lt;-\n      with(xbomsoi, SOI - trendSOI + mean(trendSOI))\n    par(fig=c(.5,1,.5,1),new=TRUE)\n    plot(detrendRain ~ detrendSOI, data = xbomsoi,\n         xlab=\"Detrended SOI\", ylab = \"Detrended rainfall\", yaxt=\"n\")\n    axis(2, at = rainpos^0.33, labels=paste(rainpos))\n    with(xbomsoi, lines(lowess(detrendRain ~ detrendSOI)))\n    attach(xbomsoi)\n    xbomsoi.ma12 &lt;- arima(detrendRain, xreg=detrendSOI,\n                          order=c(0,0,12))\n    xbomsoi.ma12s &lt;- arima(detrendRain, xreg=detrendSOI,\n                           seasonal=list(order=c(0,0,1), period=12))\n    print(xbomsoi.ma12)\n    print(xbomsoi.ma12s)\n    par(fig=c(0,0.5,0,0.5), new=TRUE)\n    acf(resid(xbomsoi.ma12))\n    par(fig=c(0.5,1,0,0.5), new=TRUE)\n    pacf(resid(xbomsoi.ma12))\n    par(oldpar)\n    detach(xbomsoi)\n  }\n\nData for further regions of Australia are available from the websites noted on the help page for bomsoi.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Answers to Selected Chapter 6 Exercises</span>"
    ]
  },
  {
    "objectID": "ch7.html",
    "href": "ch7.html",
    "title": "7  Answers to Selected Chapter 7 Exercises",
    "section": "",
    "text": "library(DAAG)\n\nThe final two sentences of Exercise 1 are challenging!\nExercises 1 & 2 should be asterisked.\n\n\nExercise 1\n\nRepeat the calculations of Subsection 7.4.5, but omitting results from two vines at random. Here is code that will handle the calculation: \n\nn.omit &lt;- 2\ntake &lt;- rep(TRUE, 48)\ntake[sample(1:48,2)] &lt;- FALSE\nkiwishade.lmer &lt;- lmer(yield ~ shade + (1|block) + (1|block:plot),\n                      data = kiwishade,subset=take)\nvcov &lt;- show(VarCorr(kiwishade.lmer))\ngps &lt;- vcov[, \"Groups\"]\nprint(vcov[gps==\"block:plot\", \"Variance\"])\nprint(vcov[gps==\"Residual\", \"Variance\"])\n\nRepeat this calculation five times, for each of n.omit = 2, 4, 6, 8, 10, 12 and 14. Plot (i) the plot component of variance and (ii) the vine component of variance, against number of points omitted. Based on these results, for what value of n.omit does the loss of vines begin to compromise results? Which of the two components of variance estimates is more damaged by the loss of observations? Comment on why this is to be expected.\n\nFor convenience, we place the central part of the calculation in a function. On slow machines, the code may take a minute or two to run.\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\ntrashvine &lt;- function(n.omit=2)\n{\n   k &lt;- k+1\n   n[k] &lt;- n.omit\n   take &lt;- rep(T, 48)\n   take[sample(1:48, n.omit)] &lt;- F\n   kiwishade$take &lt;- take\n   kiwishade.lmer &lt;- lmer(yield ~ shade + (1 | block) + (1|block:plot), \n                        data = kiwishade, subset=take)\n   varv &lt;- as.numeric(attr(VarCorr(kiwishade.lmer), \"sc\")^2)\n   varp &lt;- as.numeric(VarCorr(kiwishade.lmer)$`block:plot`)\n   c(varp, varv)\n   }\nvarp &lt;- numeric(35)\nvarv &lt;- numeric(35)\nn &lt;- numeric(35)\nk &lt;- 0\nfor(n.omit in c( 2, 4, 6, 8, 10, 12, 14))\nfor(i in 1:5){\n   k &lt;- k+1\n   vec2 &lt;- trashvine(n.omit=n.omit)\n   n[k] &lt;- n.omit\n   varp[k] &lt;- vec2[1]\n   varv[k] &lt;- vec2[2]\n}\n\nboundary (singular) fit: see help('isSingular')\n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nThe following show within, and between, plots variance estimates as functions of the number of vines that were omitted at random\n\n\n\n\n\n\n\n\n\nAs the number of vines that are omitted increases, the variance estimates can be expected to show greater variability. The effect should be most evident on the between plot variance. Inaccuracy in estimates of the between plot variance arise both from inaccuracy in the within plot sums of squares and from loss of information at the between plot level.\nAt best it is possible only to give an approximate d.f. for the between plot estimate of variance (some plots lose more vines than others), which complicates any evaluation that relies on degree of freedom considerations.\n\n\nExercise 2\n\nRepeat the previous exercise, but now omitting 1, 2, 3, 4 complete plots at random.\n\n\ntrashplot &lt;- function(n.omit=2)\n{\n   k &lt;- k+1\n   n[k] &lt;- n.omit\n   plotlev &lt;- levels(kiwishade$plot)\n   use.lev &lt;- sample(plotlev, length(plotlev)-n.omit)\n   kiwishade$take &lt;- kiwishade$plot %in% use.lev\n   kiwishade.lmer &lt;- lmer(yield ~ shade + (1 | block) + (1|block:plot), \n                        data = kiwishade, subset=take)\n   varv &lt;- as.numeric(attr(VarCorr(kiwishade.lmer), \"sc\")^2)\n   varp &lt;- as.numeric(VarCorr(kiwishade.lmer)$`block:plot`)\n   c(varp, varv)\n   }\nvarp &lt;- numeric(20)\nvarv &lt;- numeric(20)\nn &lt;- numeric(20)\nk &lt;- 0\nfor(n.omit in 1:4)\nfor(i in 1:5){\n   k &lt;- k+1\n   vec2 &lt;- trashplot(n.omit=n.omit)\n   n[k] &lt;- n.omit\n   varp[k] &lt;- vec2[1]\n   varv[k] &lt;- vec2[2]\n}\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nAgain, we plot the results. Plots show within, and between, plots variance estimates as functions of the number of whole plots (each consisting of four vines) that were omitted at random.\n\n\n\n\n\n\n\n\n\nOmission of a whole plot loses 3 d.f. out of 36 for estimation of within plot effects, and 1 degree of freedom out of 11 for the estimation of between plot effects, i.e., a slightly greater relative loss. The effect on precision will be most obvious where the d.f.\nare already smallest, i.e., for the between plot variance. The loss of information on complete plots is inherently for serious, for the estimation of the between plot variance, than the loss of partial information (albeit on a greater number of plots) as will often happen in Exercise 1.\n\n\nExercise 2\n\nThe data set Gun (MEMSS package) reports on the numbers of rounds fired per minute, by each of nine teams of gunners, each tested twice using each of two methods. In the nine teams, three were made of men with slight build, three with average, and three with heavy build. Is there a detectable difference, in number of rounds fired, between build type or between firing methods? For improving the precision of results, which would be better – to double the number of teams, or to double the number of occasions (from 2 to 4) on which each team tests each method?\n\nIt does not make much sense to look for overall differences in Method; this depends on Physique. We therefore nest Method within Physique.\n\nlibrary(MEMSS)\n\n\nAttaching package: 'MEMSS'\n\n\nThe following objects are masked from 'package:datasets':\n\n    CO2, Orange, Theoph\n\nGun.lmer &lt;- lmer(rounds~Physique/Method +(1|Team), data=Gun)\nsummary(Gun.lmer)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: rounds ~ Physique/Method + (1 | Team)\n   Data: Gun\n\nREML criterion at convergence: 127\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.15599 -0.64718  0.09981  0.63382  1.67447 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Team     (Intercept) 1.091    1.044   \n Residual             2.180    1.476   \nNumber of obs: 36, groups:  Team, 9\n\nFixed effects:\n                         Estimate Std. Error t value\n(Intercept)               23.5889     0.4922  47.922\nPhysique.L                -0.9664     0.8526  -1.133\nPhysique.Q                 0.1905     0.8526   0.223\nPhysiqueSlight:MethodM2   -8.4500     0.8524  -9.913\nPhysiqueAverage:MethodM2  -8.1000     0.8524  -9.503\nPhysiqueHeavy:MethodM2    -8.9833     0.8524 -10.539\n\nCorrelation of Fixed Effects:\n            (Intr) Phys.L Phys.Q PS:MM2 PA:MM2\nPhysique.L   0.000                            \nPhysique.Q   0.000  0.000                     \nPhysqSl:MM2 -0.289  0.353 -0.204              \nPhysqAv:MM2 -0.289  0.000  0.408  0.000       \nPhysqHv:MM2 -0.289 -0.353 -0.204  0.000  0.000\n\n\nA good way to proceed is to determine the fitted values, and present these in an interaction plot:\n\nGun.hat &lt;- fitted(Gun.lmer)\ninteraction.plot(Gun$Physique, Gun$Method, Gun.hat)\n\n\n\n\n\n\n\n\nDifferences between methods, for each of the three physiques, are strongly attested. These can be estimated within teams, allowing 24 degrees of freedom for each of these comparisons.\nClear patterns of change with Physique seem apparent in the plot. There are however too few degrees of freedom for this effect to appear statistically significant. Note however that the parameters that are given are for the lowest level of Method, i.e., for M1. Making M2 the baseline shows the effect as closer to the conventional 5% significance level.\nThe component of variance at the between teams level is of the same order of magnitude as the within teams component. Its contribution to the variance of team means (1.044\\(^2\\)) is much greater than the contribution of the within team component (1.476\\(^2\\)/4; there are 4 results per team). If comparison between physiques is the concern; it will be much more effective to double the number of teams; compare (1.044\\(^2\\)+1.476\\(^2\\)/4)/2 (=0.82) with 1.044\\(^2\\)+1.476\\(^2\\)/8 (=1.36).\n\n\nExercise 4\n\n*The data set ergoStool (MEMSS package) has data on the amount of effort needed to get up from a stool, for each of nine individuals who each tried four different types of stool. Analyse the data both using aov() and using lme(), and reconcile the two sets of output. Was there any clear winner among the types of stool, if the aim is to keep effort to a minimum?\n\nFor analysis of variance, specify\n\naov(effort~Type+Error(Subject), data=ergoStool)\n\n\nCall:\naov(formula = effort ~ Type + Error(Subject), data = ergoStool)\n\nGrand Mean: 10.25\n\nStratum 1: Subject\n\nTerms:\n                Residuals\nSum of Squares       66.5\nDeg. of Freedom         8\n\nResidual standard error: 2.883141\n\nStratum 2: Within\n\nTerms:\n                    Type Residuals\nSum of Squares  81.19444  29.05556\nDeg. of Freedom        3        24\n\nResidual standard error: 1.100295\nEstimated effects may be unbalanced\n\n\nFor testing the Type effect for statistical significance, refer (81.19/3)/(29.06/24) (=22.35) with the \\(F_{3,24}\\) distribution. The effect is highly significant.\nThis is about as far as it is possible to go with analysis of variance calculations. When Error() is specified in the aov model, R has no mechanism for extracting estimates. (There are mildly tortuous ways to extract the information, which will not be further discussed here.)\nFor use of lmer, specify\n\nsummary(lmer(effort~Type + (1|Subject), data=ergoStool))\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: effort ~ Type + (1 | Subject)\n   Data: ergoStool\n\nREML criterion at convergence: 121.1\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.80200 -0.64317  0.05783  0.70100  1.63142 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 1.775    1.332   \n Residual             1.211    1.100   \nNumber of obs: 36, groups:  Subject, 9\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   8.5556     0.5760  14.853\nTypeT2        3.8889     0.5187   7.498\nTypeT3        2.2222     0.5187   4.284\nTypeT4        0.6667     0.5187   1.285\n\nCorrelation of Fixed Effects:\n       (Intr) TypeT2 TypeT3\nTypeT2 -0.450              \nTypeT3 -0.450  0.500       \nTypeT4 -0.450  0.500  0.500\n\n\nObserve that 1.100295\\(^2\\) (Residual StdDev) is very nearly equal to 29.06/24 obtained from the analysis of variance calculation.\nAlso the Stratum 1 mean square of 66.5/8 (=8.3125) from the analysis of variance output is very nearly equal to 1.3325\\(^2\\) +1.100295\\(^2\\)/4 (= 2.078) from the lme output.\n\n\nExercise 5\n\n*In the data set MathAchieve (MEMSS package), the factors Minority (levels yes and no) and sex, and the variable SES (socio-economic status) are clearly fixed effects. Discuss how the decision whether to treat School as a fixed or as a random effect might depend on the purpose of the study? Carry out an analysis that treats School as a random effect. Are differences between schools greater than can be explained by within school variation?\n\nSchool should be treated as a random effect if the intention is to generalize results to other comparable schools. If the intention is to apply them to other pupils or classess within those same schools, it should be taken as a fixed effect.\nFor the analysis of these data, both SES and MEANSES should be included in the model. Then the coefficient of MEANSES will measure between school effects, while the coefficient of SES will measure within school effects.\n\nMathAch.lmer &lt;- lmer(MathAch ~ Minority*Sex*(MEANSES+SES) + (1|School),\n                    data=MEMSS::MathAchieve)\nMathAch.lmer\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: MathAch ~ Minority * Sex * (MEANSES + SES) + (1 | School)\n   Data: MEMSS::MathAchieve\nREML criterion at convergence: 46316.33\nRandom effects:\n Groups   Name        Std.Dev.\n School   (Intercept) 1.585   \n Residual             5.982   \nNumber of obs: 7185, groups:  School, 160\nFixed Effects:\n                (Intercept)                  MinorityYes  \n                    12.7993                      -2.6055  \n                    SexMale                      MEANSES  \n                     1.2772                       2.2365  \n                        SES          MinorityYes:SexMale  \n                     2.5085                      -0.4623  \n        MinorityYes:MEANSES              MinorityYes:SES  \n                     1.4387                      -1.1007  \n            SexMale:MEANSES                  SexMale:SES  \n                     0.5740                      -0.5166  \nMinorityYes:SexMale:MEANSES      MinorityYes:SexMale:SES  \n                    -0.7132                       0.1103  \n\n\nTo get the square roots of variance component estimates, specify:\n\nMathAch.prof &lt;- profile(MathAch.lmer, n=10000)\nconfint(MathAch.prof, parm=1:2, level=0.95)  ## Standard deviations\n\n          2.5 %   97.5 %\n.sig01 1.347259 1.821391\n.sigma 5.880940 6.078772\n\n## The following returns the variances:\napply(confint(MathAch.prof, parm=1:2, level=0.95), 2, function(x)x^2) |&gt;\n  round(2)\n\n       2.5 % 97.5 %\n.sig01  1.82   3.32\n.sigma 34.59  36.95\n\n\nThe 95% confidence interval for the between school component of variance extended, in my calculation, from 1.82 to 3.32. See lme4::pvalues for other possible ways to calculate confidence intervals.\nIf the argument parm is left unspecified, confidence intervals are returned for all parameter estimates.\nThe number of results for school varies between 14 and 67. Thus, the relative contribution to class means is 5.51 and a number that is at most 5.982429\\(^2\\)/14 = 2.56.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Answers to Selected Chapter 7 Exercises</span>"
    ]
  },
  {
    "objectID": "ch8.html",
    "href": "ch8.html",
    "title": "8  Answers to Selected Chapter 8 Exercises",
    "section": "",
    "text": "library(DAAG)\nlibrary(rpart)\n\n\n\nExercise 1\n\nRefer to the DAAG::headInjury data frame.\n\nUse the default setting in rpart() to obtain a tree-based model for predicting occurrence of clinically important brain injury, given the other variables.\nHow many splits gives the minimum cross-validation error?\nPrune the tree using the 1 standard error rule.\n\n\n\n\n\n\nset.seed(29)         ## Gives the results presented here\ninjury.rpart &lt;- rpart(clinically.important.brain.injury ~ ., \n                      data=headInjury, method=\"class\", cp=0.0001)\nplotcp(injury.rpart)\nprintcp(injury.rpart)\n\n\nClassification tree:\nrpart(formula = clinically.important.brain.injury ~ ., data = headInjury, \n    method = \"class\", cp = 1e-04)\n\nVariables actually used in tree construction:\n[1] age.65                amnesia.before        basal.skull.fracture \n[4] GCS.13                GCS.15.2hours         high.risk            \n[7] loss.of.consciousness vomiting             \n\nRoot node error: 250/3121 = 0.080103\n\nn= 3121 \n\n      CP nsplit rel error xerror     xstd\n1 0.0400      0     1.000  1.000 0.060660\n2 0.0360      2     0.920  1.008 0.060881\n3 0.0140      3     0.884  0.940 0.058965\n4 0.0080      5     0.856  0.932 0.058734\n5 0.0001     10     0.816  0.924 0.058502\n\n\n\n\n\n\n\n\n\nThe setting cp=0.0001 was reached after some experimentation.\n\nThe minimum cross-validated relative error is for nsplit=3, i.e., for a tree size of 4.\nThe one-standard-error rule likewise chooses nsplit=3, with cp=0.014. Setting cp=0.02, i.e., larger than cp for the next smallest number of splits, will prune the tree back to this size. We have\n\n\ninjury0.rpart &lt;- prune(injury.rpart, cp=0.02)\n\nWe plot the tree from (a) that shows the cross-validated relative error, and the tree obtained from (c).\n\n\n\n\n\n\n\n\n\nPlots are from the rpart analysis of the head injury data: (i) cross-validated relative error versus cp; and (ii) the tree obtained in (c).\nThere can be substantial change from one run to the next.\n\n\nExercise 2\n\nThe data set mifem is part of the larger data set in the data frame monica that we have included in our DAAG package. Use tree-based regression to predict mortality in this larger data set. What is the most immediately striking feature of your analysis? Should this be a surprise?\n\n\nmonica.rpart &lt;- rpart(outcome ~ ., data=monica, method=\"class\")\n\n\nplot(monica.rpart)\ntext(monica.rpart)\n\n\n\n\n\n\n\n\nThose who were not hospitalized were very likely to be dead! Check by examining the table:\n\ntable(monica$hosp, monica$outcome)\n\n   \n    live dead\n  y 3522  920\n  n    3 1922\n\n\n\n\nExercise 3\n\nUse tree-based regression to predict re78 in the data frame nsw74pred1 that is in our DAAG package. Compare the predictions with the multiple regression predictions in Chapter 3. [Note: The reference to a regression calculation in Chapter 3 is a mistake]\n\nIn order to reproduce the same results as given here, do:\n\nset.seed(21)\n\nCode for the initial calculation is:\n\nnsw.rpart &lt;- rpart(re78~., data=DAAG::nsw74psid1, cp=0.001)\nplotcp(nsw.rpart)\n\n\n\n\n\n\n\n\nIt is obvious that cp=0.002 will be adequate. At this point, the following is a matter of convenience, to reduce the printed output:\n\nnsw.rpart &lt;- prune(nsw.rpart, cp=0.002)\nprintcp(nsw.rpart)\n\n\nRegression tree:\nrpart(formula = re78 ~ ., data = DAAG::nsw74psid1, cp = 0.001)\n\nVariables actually used in tree construction:\n[1] age  educ re74 re75\n\nRoot node error: 6.5346e+11/2675 = 244284318\n\nn= 2675 \n\n          CP nsplit rel error  xerror     xstd\n1  0.3446296      0   1.00000 1.00109 0.046338\n2  0.1100855      1   0.65537 0.66133 0.039153\n3  0.0409403      2   0.54528 0.55537 0.033258\n4  0.0317768      3   0.50434 0.51980 0.035127\n5  0.0158188      4   0.47257 0.51599 0.035373\n6  0.0105727      5   0.45675 0.49304 0.034834\n7  0.0105337      6   0.44618 0.47727 0.034672\n8  0.0063341      7   0.43564 0.47631 0.035349\n9  0.0056603      8   0.42931 0.47566 0.035395\n10 0.0038839      9   0.42365 0.46207 0.034858\n11 0.0035516     10   0.41976 0.46316 0.035763\n12 0.0031768     11   0.41621 0.46473 0.035912\n13 0.0028300     12   0.41304 0.46682 0.035974\n14 0.0027221     13   0.41021 0.46385 0.034807\n15 0.0023286     15   0.40476 0.46397 0.034706\n16 0.0020199     16   0.40243 0.46656 0.034689\n17 0.0020000     17   0.40041 0.46756 0.034672\n\n\nThe minimum cross-validated relative error is at nsplit=12. The one standard error limit is 0.498 (=0.463+0.035). The one standard error rule suggests taking nsplit=5.\nIf we go with the one standard error rule, we have a residual variance equal to 244284318 \\(\\times\\) 0.49177 = 120131699.\nFor the estimate of residual variance from the calculations of Section 6.x, we do the following.\n\nattach(nsw74psid1)\nhere &lt;- age &lt;= 40 & re74 &lt;= 5000 & re75 &lt;= 5000 & re78 &lt; 30000\nnsw74psidA &lt;- nsw74psid1[here, ]\ndetach(nsw74psid1)\nA1.lm &lt;- lm(re78 ~ trt + (age + educ + re74 + re75) + (black +\n      hisp + marr + nodeg), data = nsw74psidA)\nsummary(A1.lm)$sigma^2\n\n[1] 40177577\n\n\nThe variance estimate is 40177577. This is about a third of the variance estimate that was obtained with tree-based regression.\n\n\nExercise 4\n\nThe complete email spam dataset is available from https://archive.ics.uci.edu/dataset/94/spambase or from the bayesreg package. Carry out a tree-based regression using all 57 available explanatory variables. Determine the change in the cross-validation estimate of predictive accuracy.\n\nWe set the random number seed to 21, to allow users to reproduce our results. In most other contexts, it will be best not to set a seed.\n\ndata('spambase', package='bayesreg')\n## For ease of labeling output, specify short names.  \n## Use the following, or do, e.g., nam &lt;- c(paste0('v',1:57), 'yesno')\nnam &lt;- c(\"make\", \"address\", \"all\", \"threeD\", \"our\", \"over\", \"remove\", \n\"internet\", \"order\", \"mail\", \"receive\", \"will\", \"people\", \"report\", \n\"addresses\", \"free\", \"business\", \"email\", \"you\", \"credit\", \"your\", \n\"font\", \"n000\", \"money\", \"hp\", \"hpl\", \"george\", \"n650\", \"lab\", \n\"labs\", \"telnet\", \"n857\", \"data\", \"n415\", \"n85\", \"technology\", \n\"n1999\", \"parts\", \"pm\", \"direct\", \"cs\", \"meeting\", \"original\", \n\"project\", \"re\", \"edu\", \"table\", \"conference\", \"semicolon\", \"leftparen\", \n\"leftbrack\", \"bang\", \"dollar\", \"hash\", \"crl.av\", \"crl.long\", \n\"crl.tot\", \"yesno\")\nnames(spambase) &lt;- nam\n\nNow load rpart and proceed with the calculations.\n\nset.seed(21)\nspam.rpart &lt;- rpart(yesno~., data=spambase, cp=0.0001, method=\"class\")\nprintcp(spam.rpart)\n\n\nClassification tree:\nrpart(formula = yesno ~ ., data = spambase, method = \"class\", \n    cp = 1e-04)\n\nVariables actually used in tree construction:\n [1] address    addresses  all        bang       business   conference\n [7] credit     crl.av     crl.long   crl.tot    cs         direct    \n[13] dollar     edu        email      font       free       george    \n[19] hash       hp         hpl        internet   lab        labs      \n[25] leftbrack  leftparen  mail       make       money      n1999     \n[31] n415       n650       n857       order      original   over      \n[37] parts      people     pm         receive    remove     report    \n[43] table      threeD     will       you        your      \n\nRoot node error: 4486/4601 = 0.97501\n\nn= 4601 \n\n           CP nsplit rel error  xerror      xstd\n1  0.00587011      0   1.00000 1.00000 0.0023604\n2  0.00222916      3   0.98239 0.98373 0.0029934\n3  0.00217343      4   0.98016 0.98417 0.0029781\n4  0.00200624      9   0.96879 0.98417 0.0029781\n5  0.00156041     11   0.96478 0.97994 0.0031198\n6  0.00133749     15   0.95854 0.97303 0.0033355\n7  0.00118888     16   0.95720 0.96991 0.0034275\n8  0.00111458     20   0.95230 0.96634 0.0035290\n9  0.00104027     29   0.94226 0.96589 0.0035414\n10 0.00100312     32   0.93914 0.96567 0.0035476\n11 0.00094739     34   0.93714 0.96322 0.0036148\n12 0.00089166     38   0.93335 0.96099 0.0036745\n13 0.00085451     42   0.92978 0.96010 0.0036981\n14 0.00080250     48   0.92465 0.95854 0.0037388\n15 0.00078021     53   0.92064 0.95698 0.0037789\n16 0.00075791     55   0.91908 0.95586 0.0038073\n17 0.00074305     69   0.90816 0.95586 0.0038073\n18 0.00066875     85   0.89523 0.95074 0.0039341\n19 0.00059444    110   0.87829 0.94739 0.0040139\n20 0.00057958    114   0.87584 0.94516 0.0040658\n21 0.00055729    119   0.87294 0.94583 0.0040504\n22 0.00052014    127   0.86848 0.94583 0.0040504\n23 0.00044583    130   0.86692 0.93914 0.0042017\n24 0.00039010    193   0.83794 0.93981 0.0041869\n25 0.00037153    197   0.83638 0.93981 0.0041869\n26 0.00035667    209   0.83148 0.93981 0.0041869\n27 0.00033437    214   0.82969 0.93981 0.0041869\n28 0.00027864    218   0.82835 0.93959 0.0041919\n29 0.00022292    226   0.82613 0.93959 0.0041919\n30 0.00011146    241   0.82278 0.93781 0.0042311\n31 0.00010000    243   0.82256 0.93803 0.0042262\n\n\nFigure @ref(spam) shows the plot of cross-validated relative error versus cp, for the full spam data set. For making a decision on the size of tree however, it is convenient to work from the information given by the function printcp().\n\nplotcp(spam.rpart)\n\n\n\n\n\n\n\n\nSetting cp=0.0001 ensures, when the random number seed is set to 21, that the cross-validated relative error reaches a minimum, of 0.1958, at nsplit=43. Pruning to get the tree that is likely to have best predictive power can use cp=0.001. Adding the SE to the minimum cross-validated relative error gives 0.2. The smallest tree with an SE smaller than this is at nsplit=36; setting cp=0.0012 will give this tree.\nHere then are the two prunings:\n\nspam.rpart1 &lt;- prune(spam.rpart, cp=0.001)  # Minimum predicted error\nspam.rpart2 &lt;- prune(spam.rpart, cp=0.0012) # 1 SE pruning",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Answers to Selected Chapter 8 Exercises</span>"
    ]
  },
  {
    "objectID": "ch9.html",
    "href": "ch9.html",
    "title": "9  Answers to Selected Chapter 9 Exercises",
    "section": "",
    "text": "Exercise 1\n\nCarry out the principal components analysis of Subsection 9.1.2, separately for males and females. For each of the first and second principal components, plot the rotations for females against the rotations for all data combined, and similarly for males. Are there any striking differences?\n\nThe help page ?loadings explains how the term loadings came to be used, rather than the term rotations that is now regarded as more appropriate in a principal components context.\nWe do the analysis (i) for all observations; (ii) for females; (iii) for males.\n\nall.pr &lt;- prcomp(na.omit(possum[, -(1:5)]))\nfemp.pr &lt;- prcomp(na.omit(possum[possum$sex==\"f\", -(1:5)]))\nmalep.pr &lt;- prcomp(na.omit(possum[possum$sex==\"m\", -(1:5)]))\n\nOne way to compare the separate rotations is to plot each set in turn against the rotations for all observations. We put the code into a function so that we can easily do the plot for each component in turn. The settings for the two elements of signs allow us to switch the signs of all elements, for males and females separately. Rotations that differ only in a change of sign in all elements are equivalent.\n\ncompare.rotations &lt;- function(i=1, all.load=all.pr$rotation,\n                             fload=femp.pr$rotation,\n                             mload=malep.pr$rotation, signs=c(1,1)){\n   alli &lt;- all.load[,i]\n   fi &lt;- fload[,i]*signs[1]\n   mi &lt;- mload[,i]*signs[2]\n   plot(range(alli), range(c(fi, mi)), type=\"n\")\n   chw &lt;- par()$cxy[1]\n   points(alli, fi, col=\"red\")\n   text(alli, fi, lab=row.names(fload), adj=0, xpd=TRUE, col=\"red\", \n        pos=2, cex=0.8)\n   points(alli, mi, col=\"blue\")\n   text(alli, mi, lab=row.names(mload), adj=0, xpd=TRUE, col=\"blue\", \n        pos=4, cex=0.8)\n   abline(0,1)                                                 \n   }\n\nNow compare the rotations for the first and second principal components. From examination of the results for default settings for signs, it is obvious that a switch of sign is needed for the male rotations.\n\npar(mfrow=c(1,2))\ncompare.rotations(1)                    # Compare rotations on 1st pc\ncompare.rotations(2, signs=c(1,-1))     # Compare rotations on 2nd pc\n\n\n\n\n\n\n\n\n\n\nRotations for females (red) and rotations for males(blue), plotted against rotations for the total data set.\n\n\nExercise 2\n\nIn the discriminant analysis for the possum data (Subsection 9.4.4), determine, for each site, the means of the scores on the first and second discriminant functions. Plot the means for the second discriminant function against the means for the first discriminant function. Identify the means with the names of the sites.\n\nWe need only omit the rows that have missing values in columns 6-14. (The variable age, in column 4, has two missing values, which are need not concern us.) Hence the use, in the code that follows, of ccases to identify rows that have no missing values in these columns. Here is the code used to do the discriminant function calculations:\n\nsuppressPackageStartupMessages(library(MASS))\nccases &lt;- complete.cases(possum[,6:14])\npossum.lda &lt;- lda(site ~ hdlngth+skullw+totlngth+ taill+footlgth+\n                  earconch+eye+chest+belly, data=possum[ccases, ])\n\nWe calculate the means of the scores thus:\n\npossum.fit &lt;- predict(possum.lda)\navfit &lt;- aggregate(possum.fit$x, by=list(possum[ccases, \"site\"]), \n                   FUN=mean)\nround(avfit,2)\n\n  Group.1   LD1   LD2   LD3   LD4   LD5   LD6\n1       1  4.41  0.56 -0.32 -0.17 -0.06 -0.01\n2       2  3.88 -1.86  0.54  0.42  0.26  0.02\n3       3 -2.61  0.67 -0.54  1.07 -0.52 -0.05\n4       4 -2.55  1.97  1.30  0.23  0.57 -0.22\n5       5 -3.95  0.18 -0.60 -0.03  0.24  0.40\n6       6 -4.28 -0.81 -1.03 -0.23  0.10 -0.30\n7       7 -2.72 -0.35  1.10 -0.29 -0.32  0.03\n\n\nThe matrix avfit has 7 rows (one for each site) and 6 columns (one for each of the six discriminant functions). The row labels can be obtained from the data frame possumsites. Here then is the plot:\n\nplot(avfit[,\"LD1\"], avfit[,\"LD2\"], xlab=\"1st discriminant function\",\n     ylab=\"2nd discriminant function\")\nchw &lt;- par()$cxy[1]\ntext(avfit[,\"LD1\"]+0.5*chw, avfit[,\"LD2\"], labels=row.names(possumsites), \n     adj=0, xpd=TRUE)\n\n\n\n\n\n\n\n\n\n\nThe graph plots of second discriminant function against the first discriminant function, for the possum data frame. The discriminant functions are designed to discriminate between sites.} Cambarville and Bellbird seem distinguised from the other sites.\n\n\nExercise 3\n\nThe data frame possumsites (DAAG package) holds latitudes, longitudes, and altitudes, for the seven sites. The following code, which assumes that the oz package is installed, locates the sites on a map that shows the Eastern Australian coastline and nearby state boundaries.\n\nlibrary(DAAG); library(oz)\noz(sections=c(3:5, 11:16))\nnames(possumsites)[1:2] &lt;- c(\"long\", \"lat\")\nwith(possumsites, points(long, lat))\nchw &lt;- par()$cxy[1]\nchh &lt;- par()$cxy[2]\nposval &lt;- c(2, 4, 2, 2, 4, 2, 2)\nwith(possumsites, text(long, lat, \n     row.names(possumsites), pos=posval))\n\n\n\n\n\n\n\n\nDo the site means that were calculated in Exercise 2 relate in any obvious way to geographical position, or to altitude?\n\nCambarville and Bellbird, which were distinguished from the main cluster in the plot in Exercise 2, are the southernmost sites.\n\n\nExercise 5\n\nCreate a version of Figure 9.15B that shows the discriminant line. In the example of Subsection 9.4.1, investigate whether use of logpet, in addition to logwid and loglen, improve discrimination?\n\nHere are the discriminant function calculations:\n\nleafshape17 &lt;- DAAG::leafshape17\nleaf17.lda &lt;- lda(arch ~ logwid + loglen, data = leafshape17)\nleaf17.fit &lt;- predict(leaf17.lda)\nleaf17.lda$prior\n\n        0         1 \n0.6721311 0.3278689 \n\nleaf17.lda$scaling\n\n             LD1\nlogwid 0.1555083\nloglen 3.0658277\n\nleaf17.lda$means\n\n    logwid   loglen\n0 1.429422 2.460128\n1 1.865537 2.993948\n\n\nThe information needed to reconstruct the discriminant function is provided by leaf17.lda$prior, leaf17.lda$means and leaf17.lda$scaling. First we calculate a grand mean, from that the constant term for the discriminant function, and then do a plot (see below) that checks that we are correctly recovering the discriminant function scores. Calculations can be done without matrix multiplication, but are tedious to write down. The following assumes a knowledge of matrix multiplication, for which the symbol is %*%:\n\ngmean &lt;- leaf17.lda$prior%*%leaf17.lda$means\nconst &lt;- as.numeric(gmean%*%leaf17.lda$scaling)\nz &lt;- as.matrix(leafshape17[,c(5,7)])%*%leaf17.lda$scaling - const\n\nNote that R distinguishes between a 1 by 1 matrix and a numeric constant. The final two lines are a check that the discriminant function has been correctly calculated. It has the form \\(ax+by-c = z\\), where the discriminant line is given by \\(z = 0\\). The equation of the line is then \\(y = -a/bx + c/b\\). We have\n\nslope &lt;- -leaf17.lda$scaling[1]/leaf17.lda$scaling[2]\nintercept &lt;- const/leaf17.lda$scaling[2]\n\nWe now show the plot that checks that we have correctly recovered the discriminant function scores, with the requested plot alongside.\n\npar(mfrow=c(1,2))\nplot(z, leaf17.fit$x[,1]); abline(0,1)\nmtext(side=3, line=1, \"Check that z=leaf17.fit$x[,1]\")\nplot(loglen ~ logwid, data=leafshape17, xlab=\"log(leaf width)\",\n     ylab=\"log(leaf length)\", pch=leafshape17$arch+1)\nabline(intercept, slope)\nmtext(side=3, line=1, \"Fig 9.4B, with discriminant line\")\n\n\n\n\n\n\n\n\n\n\nThe left panel is a check that calculations are correct. The right panel reproduces Figure 9.4B, adding the discriminant function line.\n\n\nExercise 6\n\n*The data set leafshape has three leaf measurements – bladelen (blade length), bladewid (blade width), and petiole (petiole length). These are available for each of two plant architectures, in each of six locations. (The data set leafshape17 that we encountered in Section 12.2.1 is a subset of the data set leafshape.) Use logistic regression to develop an equation for predicting architecture, given leaf dimensions and location. Compare the alternatives: (i) different discriminant functions for different locations; (ii) the same coefficients for the leaf shape variables, but different intercepts for different locations; (iii) the same coefficients for the leaf shape variables, with an intercept that is a linear function of latitude; (iv) the same equation for all locations. Interpret the equation that is finally chosen as discriminant function.\n\nWe will work with the variables logwid, loglen and logpet.\n\nleafshape &lt;- DAAG::leafshape\nnames(leafshape)[4] &lt;- \"latitude\"\none.glm &lt;- glm(arch ~ (logwid+loglen+logpet)*location, \n               family=binomial, data=leafshape)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\ntwo.glm &lt;- glm(arch ~ (logwid+loglen+logpet)+location, \n               family=binomial, data=leafshape)\nthree.glm &lt;- glm(arch ~ (logwid+loglen+logpet)*latitude, \n                 family=binomial, data=leafshape)\nfour.glm &lt;- glm(arch ~ (logwid+loglen+logpet)+latitude, \n                family=binomial, data=leafshape)\nanova(four.glm, three.glm, two.glm, one.glm)\n\nAnalysis of Deviance Table\n\nModel 1: arch ~ (logwid + loglen + logpet) + latitude\nModel 2: arch ~ (logwid + loglen + logpet) * latitude\nModel 3: arch ~ (logwid + loglen + logpet) + location\nModel 4: arch ~ (logwid + loglen + logpet) * location\n  Resid. Df Resid. Dev Df Deviance\n1       281     193.31            \n2       278     187.78  3    5.530\n3       277     186.30  1    1.481\n4       262     148.00 15   38.298\n\n\nIt may however, in view of uncertainty about the adequacy of the asymptotic chi-squared approximation for the deviance changes, be better to fit the models using lda(), and choose the model that has the smallest cross-validated relative error:\n\nlibrary(MASS)\none.lda &lt;- lda(arch ~ (logwid+loglen+logpet)*location, \n               CV=TRUE, data=leafshape)\ntwo.lda &lt;- lda(arch ~ (logwid+loglen+logpet)+location, \n               CV=TRUE, data=leafshape)\nthree.lda &lt;- lda(arch ~ (logwid+loglen+logpet)*latitude, \n                 CV=TRUE, data=leafshape)\nfour.lda &lt;- lda(arch ~ (logwid+loglen+logpet)+latitude, \n                CV=TRUE, data=leafshape)\nt1 &lt;- table(leafshape$arch, one.lda$class)\nt2 &lt;- table(leafshape$arch, two.lda$class)\nt3 &lt;- table(leafshape$arch, three.lda$class)\nt4 &lt;- table(leafshape$arch, four.lda$class)\n# Pairs of columns will now appear in order 'one', 'two', 'three', 'four'\ncbind(t1,t2,t3,t4) \n\n    0  1   0  1   0  1   0  1\n0 173 19 177 15 179 13 177 15\n1  24 70  24 70  22 72  24 70\n\n# Calculate leave-one-out cross-validation predictive accuracy estimates\nsapply(list(one=t1,two=t2,three=t3,four=t4), \n       function(x)sum(diag(x))/sum(x)) |&gt; round(2)\n\n  one   two three  four \n 0.85  0.86  0.88  0.86 \n\n\nNote that leave-one-out cross-validation gives the same result each time that the calculation is run. (How so?)\nIn all four tables, the totals of the rowsums are the totals for the respective architectures. Thus:\n\nsapply(list(one=t1,two=t2,three=t3,four=t4), \n       function(x)apply(x,1,sum))  ## Same number each time\n\n  one two three four\n0 192 192   192  192\n1  94  94    94   94\n\nsapply(list(one=t1,two=t2,three=t3,four=t4), \n       function(x)apply(x,2,sum))  ## All are not the same\n\n  one two three four\n0 197 201   201  201\n1  89  85    85   85\n\n\nThe following improves the labeling when the tables for the four models are shown side by side:\n\nt1 &lt;- table(arch=leafshape$arch, class=one.lda$class)\nt2 &lt;- table(arch=leafshape$arch, class=two.lda$class)\nt3 &lt;- table(arch=leafshape$arch, class=three.lda$class)\nt4 &lt;- table(arch=leafshape$arch, class=four.lda$class)\n## Set the four tables side by side\ntab1234 &lt;- array(cbind(t1,t2,t3,t4), dim=c(2,2,4),\n  dimnames=c(dimnames(t1), list(c('one','two','three','four'))))\nftable(tab1234, col.vars=c(3,2))\n\n           one     two     three     four    \n     class   0   1   0   1     0   1    0   1\narch                                         \n0          173  19 177  15   179  13  177  15\n1           24  70  24  70    22  72   24  70",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Answers to Selected Chapter 9 Exercises</span>"
    ]
  }
]